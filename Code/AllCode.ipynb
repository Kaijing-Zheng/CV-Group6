{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUmUwD9al4SF",
        "outputId": "1f634cc7-2681-4d5b-e0e5-8935002fcb21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mediapipe==0.10.14 in /usr/local/lib/python3.12/dist-packages (0.10.14)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (25.9.23)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (0.7.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (0.7.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (2.0.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (4.12.0.88)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.14) (0.5.3)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.14) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.14) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.14) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.14) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.14) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.14) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.14) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.14) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.14) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.14) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.14) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.14) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.14) (1.17.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.6.0\n"
          ]
        }
      ],
      "source": [
        "pip install mediapipe==0.10.14 opencv-python pillow tqdm\n",
        "pip install torch numpy scikit-learn\n",
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgUt8vxaVNV0",
        "outputId": "13e63c5a-6a57-4d6c-ed93-7e886d3728eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZdAs9nqhgNH",
        "outputId": "6ed7f459-86a3-4d94-dfb5-926b3362c5d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No --data_dir provided, using default Google Drive path: /content/drive/MyDrive/Duke University/CV-Group6/asl_alphabet_train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting train:   0%|          | 0/61001 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
            "Extracting train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61001/61001 [8:35:08<00:00,  1.97it/s]\n",
            "Extracting val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17428/17428 [2:29:21<00:00,  1.94it/s]\n",
            "Extracting test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8715/8715 [1:18:43<00:00,  1.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"data_root\": \"/content/drive/MyDrive/Duke University/CV-Group6/asl_alphabet_train\",\n",
            "  \"output_dir\": \"/content/drive/MyDrive/Duke University/CV-Group6\",\n",
            "  \"labels\": [\n",
            "    \"A\",\n",
            "    \"B\",\n",
            "    \"C\",\n",
            "    \"D\",\n",
            "    \"E\",\n",
            "    \"F\",\n",
            "    \"G\",\n",
            "    \"H\",\n",
            "    \"I\",\n",
            "    \"J\",\n",
            "    \"K\",\n",
            "    \"L\",\n",
            "    \"M\",\n",
            "    \"N\",\n",
            "    \"O\",\n",
            "    \"P\",\n",
            "    \"Q\",\n",
            "    \"R\",\n",
            "    \"S\",\n",
            "    \"T\",\n",
            "    \"U\",\n",
            "    \"V\",\n",
            "    \"W\",\n",
            "    \"X\",\n",
            "    \"Y\",\n",
            "    \"Z\",\n",
            "    \"del\",\n",
            "    \"nothing\",\n",
            "    \"space\"\n",
            "  ],\n",
            "  \"counts_after_extraction\": {\n",
            "    \"train\": 46808,\n",
            "    \"val\": 13360,\n",
            "    \"test\": 6663\n",
            "  },\n",
            "  \"splits\": {\n",
            "    \"train_ratio\": 0.7,\n",
            "    \"val_ratio\": 0.2,\n",
            "    \"test_ratio\": 0.1\n",
            "  },\n",
            "  \"feature_dim\": 42,\n",
            "  \"normalization\": \"center by mean(x,y), divide by max-abs; z removed\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "#New Mediapipe\n",
        "import os\n",
        "import json\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "from typing import List, Optional, Dict\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ‚úÖ Optional: detect if we're running in Google Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Mediapipe is required. In Colab, install with:\n",
        "# !pip install mediapipe==0.10.14 opencv-python pillow tqdm\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "mp_hands = mp.solutions.hands\n",
        "\n",
        "\n",
        "def list_images_by_label(root: Path, patterns: List[str]) -> Dict[str, List[Path]]:\n",
        "    \"\"\"\n",
        "    Assumes directory structure like:\n",
        "      root/\n",
        "        A/*.jpg\n",
        "        B/*.png\n",
        "        ...\n",
        "    Returns a dict: label -> list of image paths\n",
        "    \"\"\"\n",
        "    label_to_files = {}\n",
        "    for label_dir in sorted([p for p in root.iterdir() if p.is_dir()]):\n",
        "        files = []\n",
        "        for pat in patterns:\n",
        "            files.extend(sorted(label_dir.glob(pat)))\n",
        "        if files:\n",
        "            label_to_files[label_dir.name] = files\n",
        "    return label_to_files\n",
        "\n",
        "\n",
        "def extract_hand_landmarks(img_bgr: np.ndarray,\n",
        "                           hands_detector: mp_hands.Hands) -> Optional[np.ndarray]:\n",
        "    \"\"\"\n",
        "    Returns (21, 3) array of (x,y,z) in normalized image coordinates for the BEST hand\n",
        "    (highest detection score) or None if no hands.\n",
        "    \"\"\"\n",
        "    rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "    result = hands_detector.process(rgb)\n",
        "    if not result.multi_hand_landmarks or not result.multi_handedness:\n",
        "        return None\n",
        "\n",
        "    # choose the hand with highest score\n",
        "    scores = [h.classification[0].score for h in result.multi_handedness]\n",
        "    idx = int(np.argmax(scores))\n",
        "    hand_lms = result.multi_hand_landmarks[idx]\n",
        "\n",
        "    pts = []\n",
        "    for lm in hand_lms.landmark:\n",
        "        pts.append([lm.x, lm.y, lm.z])\n",
        "    return np.asarray(pts, dtype=np.float32)  # (21, 3)\n",
        "\n",
        "\n",
        "def clean_landmarks(pts_xyz: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Cleaning as specified:\n",
        "      - Remove z (depth)\n",
        "      - Centralize coordinates to the center point of the hand (mean of x,y over 21 landmarks)\n",
        "      - Flatten to 1D\n",
        "      - Normalize w.r.t. max absolute value (so values in [-1,1])\n",
        "    Input: (21,3) float32\n",
        "    Output: (42,) float32\n",
        "    \"\"\"\n",
        "    pts_xy = pts_xyz[:, :2]  # (21, 2)\n",
        "    center = pts_xy.mean(axis=0, keepdims=True)  # (1,2)\n",
        "    pts_centered = pts_xy - center  # (21, 2)\n",
        "    flat = pts_centered.reshape(-1)  # (42,)\n",
        "    denom = np.max(np.abs(flat))\n",
        "    if denom < 1e-12:\n",
        "        denom = 1.0\n",
        "    flat_norm = flat / denom\n",
        "    return flat_norm.astype(np.float32)\n",
        "\n",
        "\n",
        "def read_image_bgr(path: Path, max_side: Optional[int] = None) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Read with Pillow (same as original), convert to BGR for Mediapipe/OpenCV.\n",
        "    Optionally resize so the longest side == max_side to speed up processing (keeps aspect).\n",
        "    \"\"\"\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    if max_side is not None:\n",
        "        w, h = img.size\n",
        "        scale = max(w, h) / max_side\n",
        "        if scale > 1.0:\n",
        "            new_w = int(round(w / scale))\n",
        "            new_h = int(round(h / scale))\n",
        "            img = img.resize((new_w, new_h), Image.BILINEAR)\n",
        "    arr = np.array(img)  # RGB\n",
        "    bgr = arr[:, :, ::-1].copy()\n",
        "    return bgr\n",
        "\n",
        "\n",
        "def stratified_split_3way(paths: List[Path],\n",
        "                          labels: List[int],\n",
        "                          train_ratio: float = 0.7,\n",
        "                          val_ratio: float = 0.2,\n",
        "                          test_ratio: float = 0.1,\n",
        "                          seed: int = 42):\n",
        "    \"\"\"\n",
        "    Simple stratified split into train/val/test without sklearn.\n",
        "\n",
        "    Ratios must sum to ~1.0.\n",
        "    \"\"\"\n",
        "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \\\n",
        "        \"train_ratio + val_ratio + test_ratio must equal 1.0\"\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    paths = np.array(paths, dtype=object)\n",
        "    labels = np.array(labels, dtype=int)\n",
        "    unique = np.unique(labels)\n",
        "\n",
        "    train_idx, val_idx, test_idx = [], [], []\n",
        "\n",
        "    for c in unique:\n",
        "        idx = np.where(labels == c)[0]\n",
        "        rng.shuffle(idx)\n",
        "        n = len(idx)\n",
        "\n",
        "        n_train = int(round(n * train_ratio))\n",
        "        n_val   = int(round(n * val_ratio))\n",
        "        # Ensure we don't lose samples due to rounding\n",
        "        n_test  = n - n_train - n_val\n",
        "        if n_test < 0:\n",
        "            # In rare rounding issues, fix by reducing validation\n",
        "            n_test = 0\n",
        "            n_val = n - n_train\n",
        "\n",
        "        train_idx.extend(idx[:n_train])\n",
        "        val_idx.extend(idx[n_train:n_train + n_val])\n",
        "        test_idx.extend(idx[n_train + n_val:])\n",
        "\n",
        "    return (\n",
        "        paths[train_idx].tolist(), labels[train_idx].tolist(),\n",
        "        paths[val_idx].tolist(),   labels[val_idx].tolist(),\n",
        "        paths[test_idx].tolist(),  labels[test_idx].tolist(),\n",
        "    )\n",
        "\n",
        "\n",
        "def build_dataset(data_root: Path,\n",
        "                  output_dir: Path,\n",
        "                  patterns: List[str],\n",
        "                  max_side: Optional[int],\n",
        "                  min_confidence: float,\n",
        "                  static_image_mode: bool,\n",
        "                  train_ratio: float,\n",
        "                  val_ratio: float,\n",
        "                  test_ratio: float,\n",
        "                  seed: int):\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Map labels to integer ids\n",
        "    label_to_files = list_images_by_label(data_root, patterns)\n",
        "    if not label_to_files:\n",
        "        raise SystemExit(f\"No images found under {data_root}. Expected folder-per-label with images.\")\n",
        "\n",
        "    labels_sorted = sorted(label_to_files.keys())\n",
        "    label_to_id = {lab: i for i, lab in enumerate(labels_sorted)}\n",
        "    with open(output_dir / \"labels.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"labels\": labels_sorted}, f, indent=2)\n",
        "\n",
        "    # Flatten file list and labels\n",
        "    all_paths, all_labels = [], []\n",
        "    for lab, files in label_to_files.items():\n",
        "        all_paths.extend(files)\n",
        "        all_labels.extend([label_to_id[lab]] * len(files))\n",
        "\n",
        "    # Stratified split by label into train/val/test\n",
        "    (train_paths, train_labels,\n",
        "     val_paths, val_labels,\n",
        "     test_paths, test_labels) = stratified_split_3way(\n",
        "        all_paths,\n",
        "        all_labels,\n",
        "        train_ratio=train_ratio,\n",
        "        val_ratio=val_ratio,\n",
        "        test_ratio=test_ratio,\n",
        "        seed=seed,\n",
        "    )\n",
        "\n",
        "    def process_split(paths: List[Path], labels: List[int], split_name: str,\n",
        "                      hands: mp_hands.Hands):\n",
        "        xs, ys, kept = [], [], 0\n",
        "        for p, y in tqdm(zip(paths, labels), total=len(paths), desc=f\"Extracting {split_name}\"):\n",
        "            try:\n",
        "                img_bgr = read_image_bgr(p, max_side=max_side)\n",
        "                pts = extract_hand_landmarks(img_bgr, hands)\n",
        "                if pts is None:\n",
        "                    continue\n",
        "                feat = clean_landmarks(pts)  # (42,)\n",
        "                xs.append(feat)\n",
        "                ys.append(y)\n",
        "                kept += 1\n",
        "            except Exception:\n",
        "                # Skip unreadable/bad images\n",
        "                continue\n",
        "\n",
        "        if kept == 0:\n",
        "            raise SystemExit(f\"No hands found for split {split_name}. Check data or confidence settings.\")\n",
        "        X = np.stack(xs, axis=0).astype(np.float32)  # (N, 42)\n",
        "        y = np.asarray(ys, dtype=np.int64)           # (N,)\n",
        "        np.savez_compressed(output_dir / f\"{split_name}.npz\", X=X, y=y)\n",
        "        return kept\n",
        "\n",
        "    # ‚úÖ Single Mediapipe Hands instance reused for all splits\n",
        "    with mp_hands.Hands(\n",
        "        static_image_mode=static_image_mode,\n",
        "        max_num_hands=2,\n",
        "        min_detection_confidence=min_confidence\n",
        "    ) as hands:\n",
        "        ntr   = process_split(train_paths, train_labels, \"train\", hands)\n",
        "        nval  = process_split(val_paths,  val_labels,  \"val\",   hands)\n",
        "        ntest = process_split(test_paths, test_labels, \"test\",  hands)\n",
        "\n",
        "    # Write a small summary\n",
        "    summary = {\n",
        "        \"data_root\": str(data_root),\n",
        "        \"output_dir\": str(output_dir),\n",
        "        \"labels\": labels_sorted,\n",
        "        \"counts_after_extraction\": {\n",
        "            \"train\": int(ntr),\n",
        "            \"val\":   int(nval),\n",
        "            \"test\":  int(ntest),\n",
        "        },\n",
        "        \"splits\": {\n",
        "            \"train_ratio\": float(train_ratio),\n",
        "            \"val_ratio\":   float(val_ratio),\n",
        "            \"test_ratio\":  float(test_ratio),\n",
        "        },\n",
        "        \"feature_dim\": 42,\n",
        "        \"normalization\": \"center by mean(x,y), divide by max-abs; z removed\",\n",
        "    }\n",
        "    with open(output_dir / \"summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "    print(json.dumps(summary, indent=2))\n",
        "\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser(description=\"ASL Approach 2: Landmark extraction & dataset prep (fast + original-like)\")\n",
        "    ap.add_argument(\n",
        "        \"--data_dir\",\n",
        "        type=str,\n",
        "        required=False,  # allow default in Colab\n",
        "        help=(\n",
        "            \"Root folder containing subfolders per label (e.g., data/raw/A, data/raw/B, ...). \"\n",
        "            \"In Colab with Google Drive mounted, this might look like \"\n",
        "            \"'/content/drive/MyDrive/Duke University/CV-Group6/asl_alphabet_train'.\"\n",
        "        ),\n",
        "    )\n",
        "    ap.add_argument(\n",
        "        \"--output_dir\",\n",
        "        type=str,\n",
        "        default=\"/content/drive/MyDrive/Duke University/CV-Group6\",\n",
        "        help=\"Where to write train/val/test .npz, labels.json, summary.json\",\n",
        "    )\n",
        "    ap.add_argument(\n",
        "        \"--patterns\",\n",
        "        type=str,\n",
        "        nargs=\"+\",\n",
        "        default=[\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\"],\n",
        "        help=\"Glob patterns for image files per label folder\",\n",
        "    )\n",
        "    ap.add_argument(\n",
        "        \"--max_side\",\n",
        "        type=int,\n",
        "        default=512,  # same as your original behavior\n",
        "        help=\"If set, downscale images so the longest side equals this (speeds up processing)\",\n",
        "    )\n",
        "    ap.add_argument(\n",
        "        \"--min_confidence\",\n",
        "        type=float,\n",
        "        default=0.5,\n",
        "        help=\"Mediapipe min_detection_confidence\",\n",
        "    )\n",
        "    ap.add_argument(\n",
        "        \"--static_image_mode\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Use Mediapipe static image mode (recommended for photos)\",\n",
        "    )\n",
        "    ap.add_argument(\"--train_ratio\", type=float, default=0.7)\n",
        "    ap.add_argument(\"--val_ratio\",   type=float, default=0.2)\n",
        "    ap.add_argument(\"--test_ratio\",  type=float, default=0.1)\n",
        "    ap.add_argument(\"--seed\",        type=int,   default=42)\n",
        "\n",
        "    # Fix for Colab: argparse tries to parse kernel arguments like -f\n",
        "    if IN_COLAB:\n",
        "        args = ap.parse_args(args=[])\n",
        "    else:\n",
        "        args = ap.parse_args()\n",
        "\n",
        "    # If data_dir not provided, set a default Google Drive path in Colab\n",
        "    if args.data_dir is None:\n",
        "        if IN_COLAB:\n",
        "            default_drive_path = \"/content/drive/MyDrive/Duke University/CV-Group6/asl_alphabet_train\"\n",
        "            print(f\"No --data_dir provided, using default Google Drive path: {default_drive_path}\")\n",
        "            data_root = Path(default_drive_path).expanduser()\n",
        "        else:\n",
        "            raise SystemExit(\"Error: --data_dir must be provided when not running in Colab.\")\n",
        "    else:\n",
        "        data_root = Path(args.data_dir).expanduser()\n",
        "\n",
        "    output_dir = Path(args.output_dir).expanduser()\n",
        "\n",
        "    build_dataset(\n",
        "        data_root=data_root,\n",
        "        output_dir=output_dir,\n",
        "        patterns=args.patterns,\n",
        "        max_side=args.max_side,\n",
        "        min_confidence=args.min_confidence,\n",
        "        static_image_mode=args.static_image_mode,\n",
        "        train_ratio=args.train_ratio,\n",
        "        val_ratio=args.val_ratio,\n",
        "        test_ratio=args.test_ratio,\n",
        "        seed=args.seed,\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4yRrKJSBBrr",
        "outputId": "9e7a7680-2285-44de-8cbd-b844fb1f5b53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Using data directory: /content/drive/MyDrive/Duke University/CV-Group6\n",
            "üíæ Model will be saved to: /content/drive/MyDrive/Duke University/CV-Group6/asl_mlp_model.joblib\n",
            "üìä Val confusion matrix ‚Üí /content/drive/MyDrive/Duke University/CV-Group6/asl_confusion_matrix_val.png\n",
            "üìä Test confusion matrix ‚Üí /content/drive/MyDrive/Duke University/CV-Group6/asl_confusion_matrix_test.png\n",
            "‚úÖ Data loaded\n",
            "  Train samples: 46808\n",
            "  Val samples:   13360\n",
            "  Test samples:  6663\n",
            "\n",
            "üöÄ Training model on TRAIN set...\n",
            "Iteration 1, loss = 0.97324907\n",
            "Validation score: 0.926725\n",
            "Iteration 2, loss = 0.24284196\n",
            "Validation score: 0.953856\n",
            "Iteration 3, loss = 0.18433105\n",
            "Validation score: 0.956633\n",
            "Iteration 4, loss = 0.15702002\n",
            "Validation score: 0.960692\n",
            "Iteration 5, loss = 0.14014193\n",
            "Validation score: 0.961333\n",
            "Iteration 6, loss = 0.12818126\n",
            "Validation score: 0.963683\n",
            "Iteration 7, loss = 0.11819113\n",
            "Validation score: 0.964537\n",
            "Iteration 8, loss = 0.11083791\n",
            "Validation score: 0.968383\n",
            "Iteration 9, loss = 0.10512826\n",
            "Validation score: 0.965178\n",
            "Iteration 10, loss = 0.10102876\n",
            "Validation score: 0.970946\n",
            "Iteration 11, loss = 0.09612881\n",
            "Validation score: 0.970519\n",
            "Iteration 12, loss = 0.09114392\n",
            "Validation score: 0.969665\n",
            "Iteration 13, loss = 0.08860805\n",
            "Validation score: 0.970733\n",
            "Iteration 14, loss = 0.08513394\n",
            "Validation score: 0.969451\n",
            "Iteration 15, loss = 0.08175735\n",
            "Validation score: 0.972869\n",
            "Iteration 16, loss = 0.07871082\n",
            "Validation score: 0.971801\n",
            "Iteration 17, loss = 0.07634137\n",
            "Validation score: 0.973083\n",
            "Iteration 18, loss = 0.07319394\n",
            "Validation score: 0.974364\n",
            "Iteration 19, loss = 0.07232326\n",
            "Validation score: 0.974151\n",
            "Iteration 20, loss = 0.07041827\n",
            "Validation score: 0.973937\n",
            "Iteration 21, loss = 0.06723688\n",
            "Validation score: 0.976928\n",
            "Iteration 22, loss = 0.06703646\n",
            "Validation score: 0.976501\n",
            "Iteration 23, loss = 0.06434006\n",
            "Validation score: 0.975860\n",
            "Iteration 24, loss = 0.06114186\n",
            "Validation score: 0.975219\n",
            "Iteration 25, loss = 0.06017219\n",
            "Validation score: 0.974578\n",
            "Iteration 26, loss = 0.05972097\n",
            "Validation score: 0.976287\n",
            "Iteration 27, loss = 0.05714858\n",
            "Validation score: 0.974151\n",
            "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
            "\n",
            "üîé Evaluating on VALIDATION set...\n",
            "\n",
            "==============================\n",
            "‚úÖ Validation Accuracy: 0.9754\n",
            "==============================\n",
            "\n",
            "üìã Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.98      0.98      0.98       480\n",
            "           B       0.98      0.99      0.98       474\n",
            "           C       0.99      0.99      0.99       430\n",
            "           D       0.98      0.97      0.98       534\n",
            "           E       0.97      0.99      0.98       506\n",
            "           F       0.98      0.98      0.98       554\n",
            "           G       0.99      0.99      0.99       511\n",
            "           H       0.99      0.97      0.98       523\n",
            "           I       0.98      0.96      0.97       530\n",
            "           J       0.96      1.00      0.98       520\n",
            "           K       0.99      0.97      0.98       542\n",
            "           L       0.99      0.99      0.99       532\n",
            "           M       0.88      0.96      0.92       342\n",
            "           N       0.97      0.90      0.93       305\n",
            "           O       0.96      0.97      0.97       473\n",
            "           P       1.00      0.97      0.99       434\n",
            "           Q       0.98      0.98      0.98       417\n",
            "           R       0.96      0.97      0.96       526\n",
            "           S       0.97      0.97      0.97       501\n",
            "           T       0.99      0.98      0.98       508\n",
            "           U       0.96      0.94      0.95       499\n",
            "           V       0.96      0.98      0.97       518\n",
            "           W       0.98      0.96      0.97       498\n",
            "           X       0.97      0.97      0.97       481\n",
            "           Y       1.00      0.99      0.99       522\n",
            "           Z       0.99      0.99      0.99       523\n",
            "         del       0.96      0.98      0.97       332\n",
            "     nothing       0.00      0.00      0.00         0\n",
            "       space       0.97      0.99      0.98       345\n",
            "\n",
            "    accuracy                           0.98     13360\n",
            "   macro avg       0.94      0.94      0.94     13360\n",
            "weighted avg       0.98      0.98      0.98     13360\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Saved validation confusion matrix to /content/drive/MyDrive/Duke University/CV-Group6/asl_confusion_matrix_val.png\n",
            "\n",
            "==============================\n",
            "‚úÖ Validation Accuracy:   0.9754\n",
            "‚úÖ Val macro F1:          0.9742\n",
            "‚úÖ Val weighted F1:       0.9754\n",
            "==============================\n",
            "\n",
            "üìã Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.98      0.98      0.98       480\n",
            "           B       0.98      0.99      0.98       474\n",
            "           C       0.99      0.99      0.99       430\n",
            "           D       0.98      0.97      0.98       534\n",
            "           E       0.97      0.99      0.98       506\n",
            "           F       0.98      0.98      0.98       554\n",
            "           G       0.99      0.99      0.99       511\n",
            "           H       0.99      0.97      0.98       523\n",
            "           I       0.98      0.96      0.97       530\n",
            "           J       0.96      1.00      0.98       520\n",
            "           K       0.99      0.97      0.98       542\n",
            "           L       0.99      0.99      0.99       532\n",
            "           M       0.88      0.96      0.92       342\n",
            "           N       0.97      0.90      0.93       305\n",
            "           O       0.96      0.97      0.97       473\n",
            "           P       1.00      0.97      0.99       434\n",
            "           Q       0.98      0.98      0.98       417\n",
            "           R       0.96      0.97      0.96       526\n",
            "           S       0.97      0.97      0.97       501\n",
            "           T       0.99      0.98      0.98       508\n",
            "           U       0.96      0.94      0.95       499\n",
            "           V       0.96      0.98      0.97       518\n",
            "           W       0.98      0.96      0.97       498\n",
            "           X       0.97      0.97      0.97       481\n",
            "           Y       1.00      0.99      0.99       522\n",
            "           Z       0.99      0.99      0.99       523\n",
            "         del       0.96      0.98      0.97       332\n",
            "     nothing       0.00      0.00      0.00         0\n",
            "       space       0.97      0.99      0.98       345\n",
            "\n",
            "    accuracy                           0.98     13360\n",
            "   macro avg       0.94      0.94      0.94     13360\n",
            "weighted avg       0.98      0.98      0.98     13360\n",
            "\n",
            "\n",
            "üîé Evaluating on TEST set...\n",
            "\n",
            "==============================\n",
            "‚úÖ Test Accuracy: 0.9742\n",
            "==============================\n",
            "\n",
            "üìã Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.97      0.98      0.97       231\n",
            "           B       1.00      1.00      1.00       253\n",
            "           C       1.00      1.00      1.00       233\n",
            "           D       0.98      0.99      0.99       260\n",
            "           E       0.97      1.00      0.98       249\n",
            "           F       0.99      0.99      0.99       274\n",
            "           G       0.99      0.98      0.99       244\n",
            "           H       0.99      0.97      0.98       256\n",
            "           I       0.96      0.97      0.97       264\n",
            "           J       0.96      0.98      0.97       257\n",
            "           K       0.99      0.98      0.98       274\n",
            "           L       0.99      0.98      0.98       278\n",
            "           M       0.91      0.97      0.94       167\n",
            "           N       0.97      0.89      0.93       149\n",
            "           O       1.00      0.98      0.99       242\n",
            "           P       0.98      0.98      0.98       211\n",
            "           Q       1.00      0.98      0.99       221\n",
            "           R       0.92      0.97      0.95       259\n",
            "           S       0.95      0.97      0.96       253\n",
            "           T       0.96      0.97      0.96       263\n",
            "           U       0.96      0.92      0.94       235\n",
            "           V       0.96      0.95      0.95       250\n",
            "           W       0.98      0.96      0.97       245\n",
            "           X       0.97      0.95      0.96       246\n",
            "           Y       0.99      0.97      0.98       256\n",
            "           Z       1.00      0.99      0.99       267\n",
            "         del       0.95      0.99      0.97       168\n",
            "     nothing       1.00      1.00      1.00         1\n",
            "       space       0.98      0.99      0.98       157\n",
            "\n",
            "    accuracy                           0.97      6663\n",
            "   macro avg       0.97      0.97      0.97      6663\n",
            "weighted avg       0.97      0.97      0.97      6663\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Saved test confusion matrix to /content/drive/MyDrive/Duke University/CV-Group6/asl_confusion_matrix_test.png\n",
            "\n",
            "==============================\n",
            "‚úÖ Test Accuracy:         0.9742\n",
            "‚úÖ Test macro F1:         0.9741\n",
            "‚úÖ Test weighted F1:      0.9742\n",
            "==============================\n",
            "\n",
            "üìã Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.97      0.98      0.97       231\n",
            "           B       1.00      1.00      1.00       253\n",
            "           C       1.00      1.00      1.00       233\n",
            "           D       0.98      0.99      0.99       260\n",
            "           E       0.97      1.00      0.98       249\n",
            "           F       0.99      0.99      0.99       274\n",
            "           G       0.99      0.98      0.99       244\n",
            "           H       0.99      0.97      0.98       256\n",
            "           I       0.96      0.97      0.97       264\n",
            "           J       0.96      0.98      0.97       257\n",
            "           K       0.99      0.98      0.98       274\n",
            "           L       0.99      0.98      0.98       278\n",
            "           M       0.91      0.97      0.94       167\n",
            "           N       0.97      0.89      0.93       149\n",
            "           O       1.00      0.98      0.99       242\n",
            "           P       0.98      0.98      0.98       211\n",
            "           Q       1.00      0.98      0.99       221\n",
            "           R       0.92      0.97      0.95       259\n",
            "           S       0.95      0.97      0.96       253\n",
            "           T       0.96      0.97      0.96       263\n",
            "           U       0.96      0.92      0.94       235\n",
            "           V       0.96      0.95      0.95       250\n",
            "           W       0.98      0.96      0.97       245\n",
            "           X       0.97      0.95      0.96       246\n",
            "           Y       0.99      0.97      0.98       256\n",
            "           Z       1.00      0.99      0.99       267\n",
            "         del       0.95      0.99      0.97       168\n",
            "     nothing       1.00      1.00      1.00         1\n",
            "       space       0.98      0.99      0.98       157\n",
            "\n",
            "    accuracy                           0.97      6663\n",
            "   macro avg       0.97      0.97      0.97      6663\n",
            "weighted avg       0.97      0.97      0.97      6663\n",
            "\n",
            "üíæ Saved trained model to /content/drive/MyDrive/Duke University/CV-Group6/asl_mlp_model.joblib\n"
          ]
        }
      ],
      "source": [
        "# Train MLP classifier on ASL landmark vectors (Colab-friendly version) Uses SciKit\n",
        "import argparse\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import joblib\n",
        "\n",
        "# ‚úÖ Detect if running in Google Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "\n",
        "def load_npz(npz_path: Path):\n",
        "    \"\"\"Load X (features) and y (labels) from a .npz file.\"\"\"\n",
        "    data = np.load(npz_path)\n",
        "    return data[\"X\"], data[\"y\"]\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names, out_path: Path, title: str = \"Confusion Matrix\"):\n",
        "    \"\"\"Save confusion matrix as an image file.\"\"\"\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    ax = plt.gca()\n",
        "    im = ax.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n",
        "    ax.set_title(title)\n",
        "    plt.colorbar(im)\n",
        "\n",
        "    tick_marks = range(len(class_names))\n",
        "    ax.set_xticks(tick_marks)\n",
        "    ax.set_yticks(tick_marks)\n",
        "    ax.set_xticklabels(class_names, rotation=90)\n",
        "    ax.set_yticklabels(class_names)\n",
        "\n",
        "    fmt = \"d\"\n",
        "    thresh = cm.max() / 2 if cm.size else 0\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        ax.text(\n",
        "            j, i, format(cm[i, j], fmt),\n",
        "            ha=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\"\n",
        "        )\n",
        "\n",
        "    ax.set_ylabel(\"True Label\")\n",
        "    ax.set_xlabel(\"Predicted Label\")\n",
        "    plt.tight_layout()\n",
        "    out_path = Path(out_path)\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Train ASL classifier on Mediapipe landmark vectors\"\n",
        "    )\n",
        "\n",
        "    # üîß Default paths assume everything is on Google Drive when in Colab\n",
        "    if IN_COLAB:\n",
        "        base = \"/content/drive/MyDrive/Duke University/CV-Group6\"\n",
        "        default_data_dir = f\"{base}\"\n",
        "        default_model_out = f\"{base}/asl_mlp_model.joblib\"\n",
        "        default_val_cm_out = f\"{base}/asl_confusion_matrix_val.png\"\n",
        "        default_test_cm_out = f\"{base}/asl_confusion_matrix_test.png\"\n",
        "    else:\n",
        "        # Fallback defaults for local runs\n",
        "        default_data_dir = \"/content/drive/MyDrive/Duke University/CV-Group6\"\n",
        "        default_model_out = \"model.joblib\"\n",
        "        default_val_cm_out = \"confusion_matrix_val.png\"\n",
        "        default_test_cm_out = \"confusion_matrix_test.png\"\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--data_dir\",\n",
        "        type=str,\n",
        "        default=default_data_dir,\n",
        "        help=\"Folder with train.npz, val.npz, test.npz, labels.json\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model_out\",\n",
        "        type=str,\n",
        "        default=default_model_out,\n",
        "        help=\"Where to save the trained model (.joblib)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--val_cm_out\",\n",
        "        type=str,\n",
        "        default=default_val_cm_out,\n",
        "        help=\"Where to save the validation confusion matrix image (.png)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--test_cm_out\",\n",
        "        type=str,\n",
        "        default=default_test_cm_out,\n",
        "        help=\"Where to save the test confusion matrix image (.png)\",\n",
        "    )\n",
        "\n",
        "    # üß† Fix argparse for Colab (avoid parsing notebook/kernel args)\n",
        "    if IN_COLAB:\n",
        "        args = parser.parse_args(args=[])\n",
        "    else:\n",
        "        args = parser.parse_args()\n",
        "\n",
        "    data_dir = Path(args.data_dir)\n",
        "    model_out = Path(args.model_out)\n",
        "    val_cm_out = Path(args.val_cm_out)\n",
        "    test_cm_out = Path(args.test_cm_out)\n",
        "\n",
        "    print(f\"üìÇ Using data directory: {data_dir}\")\n",
        "    print(f\"üíæ Model will be saved to: {model_out}\")\n",
        "    print(f\"üìä Val confusion matrix ‚Üí {val_cm_out}\")\n",
        "    print(f\"üìä Test confusion matrix ‚Üí {test_cm_out}\")\n",
        "\n",
        "    # ---------- Load datasets ----------\n",
        "    X_train, y_train = load_npz(data_dir / \"train.npz\")\n",
        "    X_val, y_val     = load_npz(data_dir / \"val.npz\")\n",
        "    X_test, y_test   = load_npz(data_dir / \"test.npz\")\n",
        "\n",
        "    # Load label names (e.g., A, B, C, ..., space)\n",
        "    with open(data_dir / \"labels.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "        labels = json.load(f)[\"labels\"]\n",
        "\n",
        "    print(\"‚úÖ Data loaded\")\n",
        "    print(f\"  Train samples: {len(X_train)}\")\n",
        "    print(f\"  Val samples:   {len(X_val)}\")\n",
        "    print(f\"  Test samples:  {len(X_test)}\")\n",
        "\n",
        "    #Optimal HP: 'hidden_size': 343, 'num_layers': 2, 'dropout': 0.28319417648906664, 'lr': 0.0017897493066372295, 'batch_size': 64\n",
        "    # ---------- Create classifier pipeline (scale ‚Üí MLP) ----------\n",
        "    clf = Pipeline([\n",
        "        (\"scaler\", StandardScaler(with_mean=False)),\n",
        "        (\"mlp\", MLPClassifier(\n",
        "            hidden_layer_sizes=(128, 64),\n",
        "            activation=\"relu\",\n",
        "            solver=\"adam\",\n",
        "            learning_rate_init=0.001,\n",
        "            batch_size=256,\n",
        "            max_iter=50,\n",
        "            early_stopping=True,\n",
        "            n_iter_no_change=5,\n",
        "            random_state=42,\n",
        "            verbose=True,\n",
        "        )),\n",
        "    ])\n",
        "\n",
        "    # ---------- Train on TRAIN only ----------\n",
        "    print(\"\\nüöÄ Training model on TRAIN set...\")\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # ---------- Evaluate on VALIDATION set ----------\n",
        "    print(\"\\nüîé Evaluating on VALIDATION set...\")\n",
        "    y_val_pred = clf.predict(X_val)\n",
        "    val_acc = accuracy_score(y_val, y_val_pred)\n",
        "    print(\"\\n==============================\")\n",
        "    print(f\"‚úÖ Validation Accuracy: {val_acc:.4f}\")\n",
        "    print(\"==============================\")\n",
        "    print(\"\\nüìã Validation Classification Report:\")\n",
        "    print(classification_report(y_val, y_val_pred, labels=list(range(len(labels))), target_names=labels))\n",
        "\n",
        "    cm_val = confusion_matrix(y_val, y_val_pred, labels=list(range(len(labels))))\n",
        "    plot_confusion_matrix(cm_val, labels, val_cm_out, title=\"Validation Confusion Matrix\")\n",
        "    print(f\"üìä Saved validation confusion matrix to {val_cm_out}\")\n",
        "    # üîπ Macro and weighted F1 for validation\n",
        "    val_f1_macro   = f1_score(y_val, y_val_pred, average=\"macro\")\n",
        "    val_f1_weighted = f1_score(y_val, y_val_pred, average=\"weighted\")\n",
        "\n",
        "    print(\"\\n==============================\")\n",
        "    print(f\"‚úÖ Validation Accuracy:   {val_acc:.4f}\")\n",
        "    print(f\"‚úÖ Val macro F1:          {val_f1_macro:.4f}\")\n",
        "    print(f\"‚úÖ Val weighted F1:       {val_f1_weighted:.4f}\")\n",
        "    print(\"==============================\")\n",
        "\n",
        "    print(\"\\nüìã Validation Classification Report:\")\n",
        "    print(classification_report(y_val, y_val_pred, labels=list(range(len(labels))), target_names=labels))\n",
        "\n",
        "\n",
        "    # ---------- Evaluate on TEST set ----------\n",
        "    print(\"\\nüîé Evaluating on TEST set...\")\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "    test_acc = accuracy_score(y_test, y_test_pred)\n",
        "    print(\"\\n==============================\")\n",
        "    print(f\"‚úÖ Test Accuracy: {test_acc:.4f}\")\n",
        "    print(\"==============================\")\n",
        "    print(\"\\nüìã Test Classification Report:\")\n",
        "    print(classification_report(y_test, y_test_pred, labels=list(range(len(labels))), target_names=labels))\n",
        "\n",
        "    cm_test = confusion_matrix(y_test, y_test_pred, labels=list(range(len(labels))))\n",
        "    plot_confusion_matrix(cm_test, labels, test_cm_out, title=\"Test Confusion Matrix\")\n",
        "    print(f\"üìä Saved test confusion matrix to {test_cm_out}\")\n",
        "    # üîπ Macro and weighted F1 for test\n",
        "    test_f1_macro    = f1_score(y_test, y_test_pred, average=\"macro\")\n",
        "    test_f1_weighted = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
        "\n",
        "    print(\"\\n==============================\")\n",
        "    print(f\"‚úÖ Test Accuracy:         {test_acc:.4f}\")\n",
        "    print(f\"‚úÖ Test macro F1:         {test_f1_macro:.4f}\")\n",
        "    print(f\"‚úÖ Test weighted F1:      {test_f1_weighted:.4f}\")\n",
        "    print(\"==============================\")\n",
        "\n",
        "    print(\"\\nüìã Test Classification Report:\")\n",
        "    print(classification_report(y_test, y_test_pred, labels=list(range(len(labels))), target_names=labels))\n",
        "\n",
        "    # ---------- Save model ----------\n",
        "    model_out.parent.mkdir(parents=True, exist_ok=True)\n",
        "    joblib.dump(clf, model_out)\n",
        "    print(f\"üíæ Saved trained model to {model_out}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKhPMUTCGH9n",
        "outputId": "7ee27ff0-07d1-418f-8efc-6908dc724512"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Using data directory: /content/drive/MyDrive/Duke University/CV-Group6\n",
            "üíæ Model will be saved to: /content/drive/MyDrive/Duke University/CV-Group6/asl_mlp_torch_model.joblib\n",
            "üìä Val confusion matrix ‚Üí /content/drive/MyDrive/Duke University/CV-Group6/asl_confusion_matrix_val.png\n",
            "üìä Test confusion matrix ‚Üí /content/drive/MyDrive/Duke University/CV-Group6/asl_confusion_matrix_test.png\n",
            "‚úÖ Data loaded\n",
            "  Train samples: 46808\n",
            "  Val samples:   13360\n",
            "  Test samples:  6663\n",
            "üñ•Ô∏è Using device: cuda\n",
            "\n",
            "üöÄ Training PyTorch MLP on TRAIN set...\n",
            "Epoch [1/30] Train Loss: 0.3372 | Val Loss: 0.1481 Acc: 0.9580 Macro F1: 0.9558\n",
            "Epoch [2/30] Train Loss: 0.1707 | Val Loss: 0.1278 Acc: 0.9621 Macro F1: 0.9599\n",
            "Epoch [3/30] Train Loss: 0.1459 | Val Loss: 0.1050 Acc: 0.9686 Macro F1: 0.9664\n",
            "Epoch [4/30] Train Loss: 0.1325 | Val Loss: 0.1088 Acc: 0.9665 Macro F1: 0.9643\n",
            "Epoch [5/30] Train Loss: 0.1266 | Val Loss: 0.0968 Acc: 0.9709 Macro F1: 0.9361\n",
            "Epoch [6/30] Train Loss: 0.1183 | Val Loss: 0.1044 Acc: 0.9695 Macro F1: 0.9331\n",
            "Epoch [7/30] Train Loss: 0.1118 | Val Loss: 0.1030 Acc: 0.9674 Macro F1: 0.9648\n",
            "Epoch [8/30] Train Loss: 0.1090 | Val Loss: 0.0876 Acc: 0.9744 Macro F1: 0.9731\n",
            "Epoch [9/30] Train Loss: 0.1057 | Val Loss: 0.0927 Acc: 0.9710 Macro F1: 0.9694\n",
            "Epoch [10/30] Train Loss: 0.1016 | Val Loss: 0.0859 Acc: 0.9740 Macro F1: 0.9723\n",
            "Epoch [11/30] Train Loss: 0.0994 | Val Loss: 0.0890 Acc: 0.9735 Macro F1: 0.9722\n",
            "Epoch [12/30] Train Loss: 0.1010 | Val Loss: 0.0984 Acc: 0.9658 Macro F1: 0.9615\n",
            "Epoch [13/30] Train Loss: 0.0968 | Val Loss: 0.0974 Acc: 0.9717 Macro F1: 0.9697\n",
            "Epoch [14/30] Train Loss: 0.0936 | Val Loss: 0.0863 Acc: 0.9743 Macro F1: 0.9720\n",
            "Epoch [15/30] Train Loss: 0.0925 | Val Loss: 0.0987 Acc: 0.9717 Macro F1: 0.9701\n",
            "Epoch [16/30] Train Loss: 0.0903 | Val Loss: 0.0865 Acc: 0.9752 Macro F1: 0.9741\n",
            "Epoch [17/30] Train Loss: 0.0918 | Val Loss: 0.0890 Acc: 0.9753 Macro F1: 0.9736\n",
            "Epoch [18/30] Train Loss: 0.0904 | Val Loss: 0.0885 Acc: 0.9756 Macro F1: 0.9743\n",
            "Epoch [19/30] Train Loss: 0.0864 | Val Loss: 0.0827 Acc: 0.9765 Macro F1: 0.9751\n",
            "Epoch [20/30] Train Loss: 0.0857 | Val Loss: 0.0912 Acc: 0.9737 Macro F1: 0.9725\n",
            "Epoch [21/30] Train Loss: 0.0859 | Val Loss: 0.0921 Acc: 0.9748 Macro F1: 0.9730\n",
            "Epoch [22/30] Train Loss: 0.0846 | Val Loss: 0.0872 Acc: 0.9756 Macro F1: 0.9746\n",
            "Epoch [23/30] Train Loss: 0.0824 | Val Loss: 0.0874 Acc: 0.9754 Macro F1: 0.9744\n",
            "Epoch [24/30] Train Loss: 0.0823 | Val Loss: 0.0887 Acc: 0.9754 Macro F1: 0.9736\n",
            "Epoch [25/30] Train Loss: 0.0805 | Val Loss: 0.0864 Acc: 0.9784 Macro F1: 0.9771\n",
            "Epoch [26/30] Train Loss: 0.0807 | Val Loss: 0.0912 Acc: 0.9766 Macro F1: 0.9752\n",
            "Epoch [27/30] Train Loss: 0.0818 | Val Loss: 0.0900 Acc: 0.9768 Macro F1: 0.9748\n",
            "Epoch [28/30] Train Loss: 0.0824 | Val Loss: 0.0781 Acc: 0.9789 Macro F1: 0.9778\n",
            "Epoch [29/30] Train Loss: 0.0751 | Val Loss: 0.0965 Acc: 0.9746 Macro F1: 0.9731\n",
            "Epoch [30/30] Train Loss: 0.0801 | Val Loss: 0.0881 Acc: 0.9778 Macro F1: 0.9425\n",
            "\n",
            "‚úÖ Loaded best model weights (Val macro F1 = 0.9778)\n",
            "\n",
            "üîé Evaluating on VALIDATION set...\n",
            "\n",
            "==============================\n",
            "‚úÖ Validation Accuracy:   0.9778\n",
            "‚úÖ Val macro F1:          0.9425\n",
            "‚úÖ Val weighted F1:       0.9779\n",
            "==============================\n",
            "\n",
            "üìã Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.97      0.97      0.97       480\n",
            "           B       0.98      0.99      0.99       474\n",
            "           C       1.00      0.99      0.99       430\n",
            "           D       0.99      0.97      0.98       534\n",
            "           E       0.97      0.99      0.98       506\n",
            "           F       0.98      0.98      0.98       554\n",
            "           G       0.98      1.00      0.99       511\n",
            "           H       1.00      0.99      0.99       523\n",
            "           I       0.98      0.97      0.98       530\n",
            "           J       0.99      0.99      0.99       520\n",
            "           K       0.99      0.99      0.99       542\n",
            "           L       1.00      0.99      0.99       532\n",
            "           M       0.83      0.99      0.90       342\n",
            "           N       0.99      0.84      0.91       305\n",
            "           O       0.95      0.99      0.97       473\n",
            "           P       0.99      0.99      0.99       434\n",
            "           Q       0.98      0.99      0.99       417\n",
            "           R       0.98      0.97      0.97       526\n",
            "           S       0.98      0.96      0.97       501\n",
            "           T       0.97      0.98      0.98       508\n",
            "           U       0.94      0.97      0.95       499\n",
            "           V       0.99      0.96      0.97       518\n",
            "           W       0.99      0.97      0.98       498\n",
            "           X       0.97      0.97      0.97       481\n",
            "           Y       1.00      0.98      0.99       522\n",
            "           Z       0.98      1.00      0.99       523\n",
            "         del       0.98      0.98      0.98       332\n",
            "     nothing       0.00      0.00      0.00         0\n",
            "       space       0.99      0.98      0.98       345\n",
            "\n",
            "    accuracy                           0.98     13360\n",
            "   macro avg       0.94      0.94      0.94     13360\n",
            "weighted avg       0.98      0.98      0.98     13360\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Saved validation confusion matrix to /content/drive/MyDrive/Duke University/CV-Group6/asl_confusion_matrix_val.png\n",
            "\n",
            "üîé Evaluating on TEST set...\n",
            "\n",
            "==============================\n",
            "‚úÖ Test Accuracy:         0.9784\n",
            "‚úÖ Test macro F1:         0.9777\n",
            "‚úÖ Test weighted F1:      0.9784\n",
            "==============================\n",
            "\n",
            "üìã Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.97      0.97      0.97       231\n",
            "           B       1.00      1.00      1.00       253\n",
            "           C       1.00      0.98      0.99       233\n",
            "           D       0.99      0.98      0.99       260\n",
            "           E       0.99      0.98      0.98       249\n",
            "           F       1.00      0.99      0.99       274\n",
            "           G       0.99      0.99      0.99       244\n",
            "           H       0.99      0.99      0.99       256\n",
            "           I       0.97      0.98      0.98       264\n",
            "           J       0.99      0.99      0.99       257\n",
            "           K       0.98      0.99      0.99       274\n",
            "           L       1.00      0.98      0.99       278\n",
            "           M       0.86      0.99      0.92       167\n",
            "           N       0.98      0.87      0.93       149\n",
            "           O       0.98      0.99      0.99       242\n",
            "           P       0.99      0.99      0.99       211\n",
            "           Q       1.00      0.98      0.99       221\n",
            "           R       0.95      0.98      0.96       259\n",
            "           S       0.98      0.97      0.98       253\n",
            "           T       0.96      0.97      0.97       263\n",
            "           U       0.93      0.98      0.95       235\n",
            "           V       1.00      0.93      0.96       250\n",
            "           W       0.99      0.98      0.99       245\n",
            "           X       0.98      0.96      0.97       246\n",
            "           Y       0.98      0.97      0.98       256\n",
            "           Z       0.98      0.99      0.99       267\n",
            "         del       0.97      0.99      0.98       168\n",
            "     nothing       1.00      1.00      1.00         1\n",
            "       space       0.97      0.99      0.98       157\n",
            "\n",
            "    accuracy                           0.98      6663\n",
            "   macro avg       0.98      0.98      0.98      6663\n",
            "weighted avg       0.98      0.98      0.98      6663\n",
            "\n",
            "üìä Saved test confusion matrix to /content/drive/MyDrive/Duke University/CV-Group6/asl_confusion_matrix_test.png\n",
            "üíæ Saved trained PyTorch MLP + scaler to /content/drive/MyDrive/Duke University/CV-Group6/asl_mlp_torch_model.joblib\n"
          ]
        }
      ],
      "source": [
        "# Train MLP classifier on ASL landmark vectors (PyTorch version, Colab-friendly)\n",
        "import argparse\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        ")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# ‚úÖ Detect if running in Google Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "\n",
        "def load_npz(npz_path: Path):\n",
        "    \"\"\"Load X (features) and y (labels) from a .npz file.\"\"\"\n",
        "    data = np.load(npz_path)\n",
        "    return data[\"X\"], data[\"y\"]\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names, out_path: Path, title: str = \"Confusion Matrix\"):\n",
        "    \"\"\"Save confusion matrix as an image file.\"\"\"\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    ax = plt.gca()\n",
        "    im = ax.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n",
        "    ax.set_title(title)\n",
        "    plt.colorbar(im)\n",
        "\n",
        "    tick_marks = range(len(class_names))\n",
        "    ax.set_xticks(tick_marks)\n",
        "    ax.set_yticks(tick_marks)\n",
        "    ax.set_xticklabels(class_names, rotation=90)\n",
        "    ax.set_yticklabels(class_names)\n",
        "\n",
        "    fmt = \"d\"\n",
        "    thresh = cm.max() / 2 if cm.size else 0\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        ax.text(\n",
        "            j, i, format(cm[i, j], fmt),\n",
        "            ha=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\"\n",
        "        )\n",
        "\n",
        "    ax.set_ylabel(\"True Label\")\n",
        "    ax.set_xlabel(\"Predicted Label\")\n",
        "    plt.tight_layout()\n",
        "    out_path = Path(out_path)\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "# ---------- PyTorch MLP model ----------\n",
        "class MLPNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_sizes, num_classes, dropout=0.3):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        in_dim = input_dim\n",
        "\n",
        "        for h in hidden_sizes:\n",
        "            layers.append(nn.Linear(in_dim, h))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            in_dim = h\n",
        "\n",
        "        layers.append(nn.Linear(in_dim, num_classes))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, input_dim)\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Train ASL classifier on Mediapipe landmark vectors (PyTorch MLP)\"\n",
        "    )\n",
        "\n",
        "    # üîß Default paths assume everything is on Google Drive when in Colab\n",
        "    if IN_COLAB:\n",
        "        base = \"/content/drive/MyDrive/Duke University/CV-Group6\"\n",
        "        default_data_dir = f\"{base}\"\n",
        "        default_model_out = f\"{base}/asl_mlp_torch_model.joblib\"\n",
        "        default_val_cm_out = f\"{base}/asl_confusion_matrix_val.png\"\n",
        "        default_test_cm_out = f\"{base}/asl_confusion_matrix_test.png\"\n",
        "    else:\n",
        "        # Fallback defaults for local runs\n",
        "        default_data_dir = \"/content/drive/MyDrive/Duke University/CV-Group6\"\n",
        "        default_model_out = \"asl_mlp_torch_model.joblib\"\n",
        "        default_val_cm_out = \"confusion_matrix_val.png\"\n",
        "        default_test_cm_out = \"confusion_matrix_test.png\"\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--data_dir\",\n",
        "        type=str,\n",
        "        default=default_data_dir,\n",
        "        help=\"Folder with train.npz, val.npz, test.npz, labels.json\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model_out\",\n",
        "        type=str,\n",
        "        default=default_model_out,\n",
        "        help=\"Where to save the trained model + scaler (joblib)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--val_cm_out\",\n",
        "        type=str,\n",
        "        default=default_val_cm_out,\n",
        "        help=\"Where to save the validation confusion matrix image (.png)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--test_cm_out\",\n",
        "        type=str,\n",
        "        default=default_test_cm_out,\n",
        "        help=\"Where to save the test confusion matrix image (.png)\",\n",
        "    )\n",
        "\n",
        "    # üß† Fix argparse for Colab (avoid parsing notebook/kernel args)\n",
        "    if IN_COLAB:\n",
        "        args = parser.parse_args(args=[])\n",
        "    else:\n",
        "        args = parser.parse_args()\n",
        "\n",
        "    data_dir = Path(args.data_dir)\n",
        "    model_out = Path(args.model_out)\n",
        "    val_cm_out = Path(args.val_cm_out)\n",
        "    test_cm_out = Path(args.test_cm_out)\n",
        "\n",
        "    print(f\"üìÇ Using data directory: {data_dir}\")\n",
        "    print(f\"üíæ Model will be saved to: {model_out}\")\n",
        "    print(f\"üìä Val confusion matrix ‚Üí {val_cm_out}\")\n",
        "    print(f\"üìä Test confusion matrix ‚Üí {test_cm_out}\")\n",
        "\n",
        "    # ---------- Load datasets ----------\n",
        "    X_train, y_train = load_npz(data_dir / \"train.npz\")\n",
        "    X_val, y_val     = load_npz(data_dir / \"val.npz\")\n",
        "    X_test, y_test   = load_npz(data_dir / \"test.npz\")\n",
        "\n",
        "    # Load label names (e.g., A, B, C, ..., space)\n",
        "    with open(data_dir / \"labels.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "        labels = json.load(f)[\"labels\"]\n",
        "\n",
        "    print(\"‚úÖ Data loaded\")\n",
        "    print(f\"  Train samples: {len(X_train)}\")\n",
        "    print(f\"  Val samples:   {len(X_val)}\")\n",
        "    print(f\"  Test samples:  {len(X_test)}\")\n",
        "\n",
        "    # ---------- Scale features (like before) ----------\n",
        "    scaler = StandardScaler(with_mean=False)\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_val_scaled   = scaler.transform(X_val)\n",
        "    X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "    # ---------- Convert to torch tensors ----------\n",
        "    X_train_t = torch.from_numpy(X_train_scaled.astype(np.float32))\n",
        "    y_train_t = torch.from_numpy(y_train.astype(np.int64))\n",
        "\n",
        "    X_val_t = torch.from_numpy(X_val_scaled.astype(np.float32))\n",
        "    y_val_t = torch.from_numpy(y_val.astype(np.int64))\n",
        "\n",
        "    X_test_t = torch.from_numpy(X_test_scaled.astype(np.float32))\n",
        "    y_test_t = torch.from_numpy(y_test.astype(np.int64))\n",
        "\n",
        "    # ---------- Datasets & Dataloaders ----------\n",
        "    # Optimal HP (from Optuna; mapped to PyTorch):\n",
        "    # 'hidden_size': 343, 'num_layers': 2, 'dropout': 0.283..., 'lr': 0.001789..., 'batch_size': 64\n",
        "    batch_size = 64\n",
        "\n",
        "    train_ds = TensorDataset(X_train_t, y_train_t)\n",
        "    val_ds   = TensorDataset(X_val_t, y_val_t)\n",
        "    test_ds  = TensorDataset(X_test_t, y_test_t)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
        "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    input_dim   = X_train_t.shape[1]\n",
        "    num_classes = len(labels)\n",
        "\n",
        "    # ---------- Set up device ----------\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"üñ•Ô∏è Using device: {device}\")\n",
        "\n",
        "    # ---------- Initialize PyTorch MLP ----------\n",
        "    hidden_sizes = [343, 343]   # from 'hidden_size' and 'num_layers' in Optuna\n",
        "    dropout = 0.28319417648906664\n",
        "    lr = 0.0017897493066372295\n",
        "\n",
        "    model = MLPNet(\n",
        "        input_dim=input_dim,\n",
        "        hidden_sizes=hidden_sizes,\n",
        "        num_classes=num_classes,\n",
        "        dropout=dropout,\n",
        "    ).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    num_epochs = 30\n",
        "    best_val_f1 = -1.0\n",
        "    best_state_dict = None\n",
        "\n",
        "    # ---------- Training loop ----------\n",
        "    print(\"\\nüöÄ Training PyTorch MLP on TRAIN set...\")\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total = 0\n",
        "\n",
        "        for xb, yb in train_loader:\n",
        "            xb = xb.to(device)\n",
        "            yb = yb.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * xb.size(0)\n",
        "            total += xb.size(0)\n",
        "\n",
        "        train_loss = running_loss / total\n",
        "\n",
        "        # ---- Validation each epoch (for monitoring) ----\n",
        "        model.eval()\n",
        "        all_val_preds = []\n",
        "        all_val_labels = []\n",
        "        val_loss = 0.0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb = xb.to(device)\n",
        "                yb = yb.to(device)\n",
        "                logits = model(xb)\n",
        "                loss = criterion(logits, yb)\n",
        "\n",
        "                val_loss += loss.item() * xb.size(0)\n",
        "                val_total += xb.size(0)\n",
        "\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                all_val_preds.extend(preds.cpu().numpy())\n",
        "                all_val_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "        val_loss /= val_total\n",
        "        val_acc = accuracy_score(all_val_labels, all_val_preds)\n",
        "        val_f1_macro = f1_score(all_val_labels, all_val_preds, average=\"macro\")\n",
        "\n",
        "        # Track best model by macro F1\n",
        "        if val_f1_macro > best_val_f1:\n",
        "            best_val_f1 = val_f1_macro\n",
        "            best_state_dict = model.state_dict()\n",
        "\n",
        "        print(\n",
        "            f\"Epoch [{epoch}/{num_epochs}] \"\n",
        "            f\"Train Loss: {train_loss:.4f} | \"\n",
        "            f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f} Macro F1: {val_f1_macro:.4f}\"\n",
        "        )\n",
        "\n",
        "    # Load best weights (based on val macro F1)\n",
        "    if best_state_dict is not None:\n",
        "        model.load_state_dict(best_state_dict)\n",
        "        print(f\"\\n‚úÖ Loaded best model weights (Val macro F1 = {best_val_f1:.4f})\")\n",
        "\n",
        "    # ---------- Final evaluation on VALIDATION set ----------\n",
        "    print(\"\\nüîé Evaluating on VALIDATION set...\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_logits = model(X_val_t.to(device))\n",
        "        val_preds = torch.argmax(val_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    val_acc = accuracy_score(y_val, val_preds)\n",
        "    val_f1_macro   = f1_score(y_val, val_preds, average=\"macro\")\n",
        "    val_f1_weighted = f1_score(y_val, val_preds, average=\"weighted\")\n",
        "\n",
        "    print(\"\\n==============================\")\n",
        "    print(f\"‚úÖ Validation Accuracy:   {val_acc:.4f}\")\n",
        "    print(f\"‚úÖ Val macro F1:          {val_f1_macro:.4f}\")\n",
        "    print(f\"‚úÖ Val weighted F1:       {val_f1_weighted:.4f}\")\n",
        "    print(\"==============================\")\n",
        "\n",
        "    print(\"\\nüìã Validation Classification Report:\")\n",
        "    print(classification_report(y_val, val_preds, labels=list(range(len(labels))), target_names=labels))\n",
        "\n",
        "    cm_val = confusion_matrix(y_val, val_preds, labels=list(range(len(labels))))\n",
        "    plot_confusion_matrix(cm_val, labels, val_cm_out, title=\"Validation Confusion Matrix\")\n",
        "    print(f\"üìä Saved validation confusion matrix to {val_cm_out}\")\n",
        "\n",
        "    # ---------- Final evaluation on TEST set ----------\n",
        "    print(\"\\nüîé Evaluating on TEST set...\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_logits = model(X_test_t.to(device))\n",
        "        test_preds = torch.argmax(test_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    test_acc = accuracy_score(y_test, test_preds)\n",
        "    test_f1_macro    = f1_score(y_test, test_preds, average=\"macro\")\n",
        "    test_f1_weighted = f1_score(y_test, test_preds, average=\"weighted\")\n",
        "\n",
        "    print(\"\\n==============================\")\n",
        "    print(f\"‚úÖ Test Accuracy:         {test_acc:.4f}\")\n",
        "    print(f\"‚úÖ Test macro F1:         {test_f1_macro:.4f}\")\n",
        "    print(f\"‚úÖ Test weighted F1:      {test_f1_weighted:.4f}\")\n",
        "    print(\"==============================\")\n",
        "\n",
        "    print(\"\\nüìã Test Classification Report:\")\n",
        "    print(classification_report(y_test, test_preds, labels=list(range(len(labels))), target_names=labels))\n",
        "\n",
        "    cm_test = confusion_matrix(y_test, test_preds, labels=list(range(len(labels))))\n",
        "    plot_confusion_matrix(cm_test, labels, test_cm_out, title=\"Test Confusion Matrix\")\n",
        "    print(f\"üìä Saved test confusion matrix to {test_cm_out}\")\n",
        "\n",
        "    # ---------- Save model + scaler ----------\n",
        "    model_out.parent.mkdir(parents=True, exist_ok=True)\n",
        "    save_obj = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"input_dim\": input_dim,\n",
        "        \"hidden_sizes\": hidden_sizes,\n",
        "        \"num_classes\": num_classes,\n",
        "        \"dropout\": dropout,\n",
        "        \"scaler\": scaler,\n",
        "        \"labels\": labels,\n",
        "    }\n",
        "    joblib.dump(save_obj, model_out)\n",
        "    print(f\"üíæ Saved trained PyTorch MLP + scaler to {model_out}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcZNZc4MMLXc",
        "outputId": "f2f989ce-16fd-4ae2-8d3a-c7b76d78d644"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPU: NVIDIA A100-SXM4-80GB\n",
            "Number of classes: 29\n",
            "Epoch [1/30] Train Loss: 0.9381 Acc: 0.712 | Val Loss: 0.2808 Acc: 0.915 F1(macro): 0.905 F1(weighted): 0.913\n",
            "Epoch [2/30] Train Loss: 0.2803 Acc: 0.924 | Val Loss: 0.1855 Acc: 0.946 F1(macro): 0.942 F1(weighted): 0.946\n",
            "Epoch [3/30] Train Loss: 0.2209 Acc: 0.937 | Val Loss: 0.1585 Acc: 0.953 F1(macro): 0.950 F1(weighted): 0.953\n",
            "Epoch [4/30] Train Loss: 0.1869 Acc: 0.948 | Val Loss: 0.1478 Acc: 0.954 F1(macro): 0.950 F1(weighted): 0.954\n",
            "Epoch [5/30] Train Loss: 0.1704 Acc: 0.951 | Val Loss: 0.1265 Acc: 0.961 F1(macro): 0.958 F1(weighted): 0.961\n",
            "Epoch [6/30] Train Loss: 0.1565 Acc: 0.956 | Val Loss: 0.1172 Acc: 0.965 F1(macro): 0.963 F1(weighted): 0.965\n",
            "Epoch [7/30] Train Loss: 0.1435 Acc: 0.959 | Val Loss: 0.1124 Acc: 0.967 F1(macro): 0.966 F1(weighted): 0.968\n",
            "Epoch [8/30] Train Loss: 0.1350 Acc: 0.961 | Val Loss: 0.1083 Acc: 0.968 F1(macro): 0.965 F1(weighted): 0.968\n",
            "Epoch [9/30] Train Loss: 0.1292 Acc: 0.963 | Val Loss: 0.1088 Acc: 0.968 F1(macro): 0.966 F1(weighted): 0.968\n",
            "Epoch [10/30] Train Loss: 0.1207 Acc: 0.964 | Val Loss: 0.0981 Acc: 0.971 F1(macro): 0.969 F1(weighted): 0.971\n",
            "Epoch [11/30] Train Loss: 0.1193 Acc: 0.964 | Val Loss: 0.0971 Acc: 0.972 F1(macro): 0.971 F1(weighted): 0.972\n",
            "Epoch [12/30] Train Loss: 0.1136 Acc: 0.966 | Val Loss: 0.0967 Acc: 0.970 F1(macro): 0.967 F1(weighted): 0.970\n",
            "Epoch [13/30] Train Loss: 0.1076 Acc: 0.966 | Val Loss: 0.0920 Acc: 0.974 F1(macro): 0.973 F1(weighted): 0.974\n",
            "Epoch [14/30] Train Loss: 0.1046 Acc: 0.968 | Val Loss: 0.0926 Acc: 0.971 F1(macro): 0.970 F1(weighted): 0.971\n",
            "Epoch [15/30] Train Loss: 0.1015 Acc: 0.969 | Val Loss: 0.0872 Acc: 0.973 F1(macro): 0.972 F1(weighted): 0.973\n",
            "Epoch [16/30] Train Loss: 0.0976 Acc: 0.970 | Val Loss: 0.0867 Acc: 0.972 F1(macro): 0.971 F1(weighted): 0.972\n",
            "Epoch [17/30] Train Loss: 0.0961 Acc: 0.971 | Val Loss: 0.0873 Acc: 0.974 F1(macro): 0.973 F1(weighted): 0.974\n",
            "Epoch [18/30] Train Loss: 0.0933 Acc: 0.972 | Val Loss: 0.0823 Acc: 0.975 F1(macro): 0.974 F1(weighted): 0.975\n",
            "Epoch [19/30] Train Loss: 0.0895 Acc: 0.972 | Val Loss: 0.0817 Acc: 0.975 F1(macro): 0.974 F1(weighted): 0.975\n",
            "Epoch [20/30] Train Loss: 0.0870 Acc: 0.973 | Val Loss: 0.0839 Acc: 0.974 F1(macro): 0.973 F1(weighted): 0.974\n",
            "Epoch [21/30] Train Loss: 0.0860 Acc: 0.973 | Val Loss: 0.0807 Acc: 0.976 F1(macro): 0.974 F1(weighted): 0.976\n",
            "Epoch [22/30] Train Loss: 0.0807 Acc: 0.974 | Val Loss: 0.0817 Acc: 0.975 F1(macro): 0.974 F1(weighted): 0.975\n",
            "Epoch [23/30] Train Loss: 0.0837 Acc: 0.974 | Val Loss: 0.0804 Acc: 0.976 F1(macro): 0.975 F1(weighted): 0.976\n",
            "Epoch [24/30] Train Loss: 0.0785 Acc: 0.975 | Val Loss: 0.0809 Acc: 0.976 F1(macro): 0.975 F1(weighted): 0.976\n",
            "Epoch [25/30] Train Loss: 0.0776 Acc: 0.975 | Val Loss: 0.0781 Acc: 0.976 F1(macro): 0.974 F1(weighted): 0.976\n",
            "Epoch [26/30] Train Loss: 0.0743 Acc: 0.977 | Val Loss: 0.0795 Acc: 0.977 F1(macro): 0.975 F1(weighted): 0.977\n",
            "Epoch [27/30] Train Loss: 0.0718 Acc: 0.977 | Val Loss: 0.0769 Acc: 0.978 F1(macro): 0.977 F1(weighted): 0.978\n",
            "Epoch [28/30] Train Loss: 0.0711 Acc: 0.976 | Val Loss: 0.0775 Acc: 0.977 F1(macro): 0.976 F1(weighted): 0.977\n",
            "Epoch [29/30] Train Loss: 0.0698 Acc: 0.977 | Val Loss: 0.0765 Acc: 0.977 F1(macro): 0.975 F1(weighted): 0.977\n",
            "Epoch [30/30] Train Loss: 0.0691 Acc: 0.978 | Val Loss: 0.0764 Acc: 0.977 F1(macro): 0.976 F1(weighted): 0.977\n",
            "\n",
            "Test Loss: 0.0782 | Test Acc: 0.978\n",
            "Test F1(macro): 0.978 | Test F1(weighted): 0.978\n",
            "\n",
            "Classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97       231\n",
            "           1       0.99      1.00      0.99       253\n",
            "           2       0.99      0.99      0.99       233\n",
            "           3       1.00      0.98      0.99       260\n",
            "           4       0.98      1.00      0.99       249\n",
            "           5       1.00      0.99      0.99       274\n",
            "           6       0.99      0.99      0.99       244\n",
            "           7       0.99      0.98      0.99       256\n",
            "           8       0.98      0.99      0.98       264\n",
            "           9       0.99      0.98      0.99       257\n",
            "          10       0.99      0.99      0.99       274\n",
            "          11       1.00      0.98      0.99       278\n",
            "          12       0.90      0.96      0.93       167\n",
            "          13       0.98      0.88      0.93       149\n",
            "          14       0.98      0.98      0.98       242\n",
            "          15       0.96      0.99      0.97       211\n",
            "          16       0.99      0.99      0.99       221\n",
            "          17       0.97      0.97      0.97       259\n",
            "          18       0.96      0.97      0.97       253\n",
            "          19       0.96      0.98      0.97       263\n",
            "          20       0.97      0.94      0.95       235\n",
            "          21       0.96      0.96      0.96       250\n",
            "          22       0.98      0.98      0.98       245\n",
            "          23       0.97      0.97      0.97       246\n",
            "          24       0.98      0.97      0.98       256\n",
            "          25       0.99      1.00      0.99       267\n",
            "          26       0.99      0.98      0.99       168\n",
            "          27       1.00      1.00      1.00         1\n",
            "          28       0.96      0.99      0.98       157\n",
            "\n",
            "    accuracy                           0.98      6663\n",
            "   macro avg       0.98      0.98      0.98      6663\n",
            "weighted avg       0.98      0.98      0.98      6663\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#LSTM Model from ChatGPT\n",
        "# ============================================================\n",
        "# 1. Imports\n",
        "# ============================================================\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "# ============================================================\n",
        "# 2. GPU setup (works in Google Colab if GPU is enabled)\n",
        "#    In Colab: Runtime -> Change runtime type -> Hardware accelerator: GPU\n",
        "# ============================================================\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "# ============================================================\n",
        "# 3. Dataset class for NPZ files: train.npz / val.npz / test.npz\n",
        "# ============================================================\n",
        "class ASLLandmarkDataset(Dataset):\n",
        "    def __init__(self, npz_path):\n",
        "        \"\"\"\n",
        "        Expects an .npz with:\n",
        "          - X: (N, 42) where 42 = 21 landmarks * 2 (x,y) coordinates\n",
        "          - y: (N,)\n",
        "        \"\"\"\n",
        "        data = np.load(npz_path)\n",
        "        self.X = data[\"X\"]  # shape: (N, 42)\n",
        "        self.y = data[\"y\"]  # shape: (N,)\n",
        "\n",
        "        assert len(self.X) == len(self.y), \"X and y must have same length\"\n",
        "        # Assertions updated for (N, 42) shape\n",
        "        assert self.X.ndim == 2, f\"X must be 2-dimensional (N, features), but got {self.X.ndim} dimensions\"\n",
        "        assert self.X.shape[1] == 42, f\"Expected 42 features per sample, but got {self.X.shape[1]}\"\n",
        "\n",
        "        # Reshape for LSTM: (N, 42) -> (N, T=1, features=42)\n",
        "        # Each static image is treated as a sequence of length 1\n",
        "        self.X = self.X[:, np.newaxis, :].astype(np.float32) # Shape becomes (N, 1, 42)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.X[idx]              # (T=1, features=42)\n",
        "        y = self.y[idx]              # scalar label\n",
        "        x = torch.from_numpy(x)      # float32 tensor\n",
        "        y = torch.tensor(y, dtype=torch.long)\n",
        "        return x, y\n",
        "\n",
        "# ============================================================\n",
        "# 4. LSTM model definition\n",
        "# ============================================================\n",
        "class ASLLSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_size=42, hidden_size=128, num_layers=2, num_classes=26, dropout=0.3):\n",
        "        \"\"\"\n",
        "        input_size: features per time step (21 landmarks * 2 coords = 42)\n",
        "        hidden_size: LSTM hidden dimension\n",
        "        num_layers: number of stacked LSTM layers\n",
        "        num_classes: number of ASL classes\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, T, input_size)\n",
        "        out, (h_n, c_n) = self.lstm(x)\n",
        "        # h_n: (num_layers, batch, hidden_size)\n",
        "        last_hidden = h_n[-1]  # (batch, hidden_size)\n",
        "        logits = self.fc(last_hidden)\n",
        "        return logits\n",
        "\n",
        "# ============================================================\n",
        "# 5. Create datasets and dataloaders for train / val / test\n",
        "# ============================================================\n",
        "train_path = \"/content/drive/MyDrive/Duke University/CV-Group6/train.npz\"\n",
        "val_path   = \"/content/drive/MyDrive/Duke University/CV-Group6/val.npz\"\n",
        "test_path  = \"/content/drive/MyDrive/Duke University/CV-Group6/test.npz\"\n",
        "\n",
        "train_dataset = ASLLandmarkDataset(train_path)\n",
        "val_dataset   = ASLLandmarkDataset(val_path)\n",
        "test_dataset  = ASLLandmarkDataset(test_path)\n",
        "\n",
        "# Infer num_classes from training labels\n",
        "num_classes = len(np.unique(train_dataset.y))\n",
        "print(\"Number of classes:\", num_classes)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# ============================================================\n",
        "# 6. Initialize model, loss, optimizer\n",
        "# ============================================================\n",
        "model = ASLLSTMClassifier(\n",
        "    input_size=42, # Changed from 63 to 42\n",
        "    hidden_size=128,\n",
        "    num_layers=2,\n",
        "    num_classes=num_classes,\n",
        "    dropout=0.3\n",
        ").to(device)  # move model to GPU/CPU\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "num_epochs = 30\n",
        "\n",
        "# ============================================================\n",
        "# 7. Training + validation loop (with F1 on val)\n",
        "# ============================================================\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # ---- Training ----\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(X_batch)\n",
        "        loss = criterion(logits, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * X_batch.size(0)\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        correct += (preds == y_batch).sum().item()\n",
        "        total += y_batch.size(0)\n",
        "\n",
        "    train_loss = running_loss / total\n",
        "    train_acc = correct / total\n",
        "\n",
        "    # ---- Validation ----\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    all_val_preds = []\n",
        "    all_val_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            logits = model(X_batch)\n",
        "            loss = criterion(logits, y_batch)\n",
        "\n",
        "            val_loss += loss.item() * X_batch.size(0)\n",
        "            _, preds = torch.max(logits, dim=1)\n",
        "            val_correct += (preds == y_batch).sum().item()\n",
        "            val_total += y_batch.size(0)\n",
        "\n",
        "            all_val_preds.extend(preds.cpu().numpy())\n",
        "            all_val_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "    val_loss /= val_total\n",
        "    val_acc = val_correct / val_total\n",
        "\n",
        "    # F1 scores on validation\n",
        "    val_f1_macro = f1_score(all_val_labels, all_val_preds, average=\"macro\")\n",
        "    val_f1_weighted = f1_score(all_val_labels, all_val_preds, average=\"weighted\")\n",
        "\n",
        "    print(\n",
        "        f\"Epoch [{epoch}/{num_epochs}] \"\n",
        "        f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.3f} | \"\n",
        "        f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.3f} \"\n",
        "        f\"F1(macro): {val_f1_macro:.3f} F1(weighted): {val_f1_weighted:.3f}\"\n",
        "    )\n",
        "\n",
        "# ============================================================\n",
        "# 8. Final evaluation on test set (with F1 + report)\n",
        "# ============================================================\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "all_test_preds = []\n",
        "all_test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        logits = model(X_batch)\n",
        "        loss = criterion(logits, y_batch)\n",
        "\n",
        "        test_loss += loss.item() * X_batch.size(0)\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        test_correct += (preds == y_batch).sum().item()\n",
        "        test_total += y_batch.size(0)\n",
        "\n",
        "        all_test_preds.extend(preds.cpu().numpy())\n",
        "        all_test_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "test_loss /= test_total\n",
        "test_acc = test_correct / test_total\n",
        "\n",
        "test_f1_macro = f1_score(all_test_labels, all_test_preds, average=\"macro\")\n",
        "test_f1_weighted = f1_score(all_test_labels, all_test_preds, average=\"weighted\")\n",
        "\n",
        "print(f\"\\nTest Loss: {test_loss:.4f} | Test Acc: {test_acc:.3f}\")\n",
        "print(f\"Test F1(macro): {test_f1_macro:.3f} | Test F1(weighted): {test_f1_weighted:.3f}\")\n",
        "\n",
        "print(\"\\nClassification report:\\n\")\n",
        "print(classification_report(all_test_labels, all_test_preds))\n",
        "\n",
        "# ============================================================\n",
        "# 9. Optional: helper to predict a single sequence\n",
        "# ============================================================\n",
        "def predict_single_sequence(model, single_sample_features_np):\n",
        "    \"\"\"\n",
        "    single_sample_features_np: numpy array of shape (42,) for one example (x,y coords)\n",
        "    returns: predicted class index (int)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Reshape (42,) to (1, 1, 42) for batch=1, T=1, input_size=42\n",
        "        x = torch.from_numpy(single_sample_features_np[np.newaxis, np.newaxis, :]).to(device)\n",
        "        logits = model(x)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        pred = torch.argmax(probs, dim=1).item()\n",
        "    return pred\n",
        "\n",
        "# Example usage (uncomment when you have test data loaded):\n",
        "# You can use a sample from the dataset's raw X array (which has shape (N, 42))\n",
        "# For example, to predict the first sample:\n",
        "# example_features = test_dataset.X_raw[0] # Assuming X_raw is the (N,42) array\n",
        "# print(\"Predicted class:\", predict_single_sequence(model, example_features))\n",
        "\n",
        "# If you want to use the processed dataset output, you'd access it like:\n",
        "# example_features_processed = test_dataset.X[0].squeeze().numpy() # This gives (42,)\n",
        "# print(\"Predicted class:\", predict_single_sequence(model, example_features_processed))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgf9eQLOMVzT",
        "outputId": "aa06a107-78fc-485d-c0bc-12a2d920d6c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-05 05:14:40,395] A new study created in memory with name: no-name-a05d0446-62fb-4e9e-95fe-50d27eb2f4f4\n",
            "[I 2025-12-05 05:14:50,745] Trial 0 finished with value: 0.1425960822722423 and parameters: {'hidden_size': 140, 'num_layers': 2, 'dropout': 0.36329921034641965, 'lr': 0.0017858593593998095, 'batch_size': 128}. Best is trial 0 with value: 0.1425960822722423.\n",
            "[I 2025-12-05 05:14:59,480] Trial 1 finished with value: 0.25707441852344365 and parameters: {'hidden_size': 149, 'num_layers': 3, 'dropout': 0.4125901349768505, 'lr': 0.00019647213314477865, 'batch_size': 64}. Best is trial 0 with value: 0.1425960822722423.\n",
            "[I 2025-12-05 05:15:11,239] Trial 2 finished with value: 0.134058354906933 and parameters: {'hidden_size': 477, 'num_layers': 1, 'dropout': 0.11528568496839108, 'lr': 0.0005299314203444907, 'batch_size': 32}. Best is trial 2 with value: 0.134058354906933.\n",
            "[I 2025-12-05 05:15:19,197] Trial 3 finished with value: 0.13388605746189633 and parameters: {'hidden_size': 195, 'num_layers': 2, 'dropout': 0.22149125065678363, 'lr': 0.0006961003231255281, 'batch_size': 64}. Best is trial 3 with value: 0.13388605746189633.\n",
            "[I 2025-12-05 05:15:30,705] Trial 4 finished with value: 0.17550329294998177 and parameters: {'hidden_size': 238, 'num_layers': 1, 'dropout': 0.47650117334399955, 'lr': 0.00048150261492466606, 'batch_size': 32}. Best is trial 3 with value: 0.13388605746189633.\n",
            "[I 2025-12-05 05:15:39,296] Trial 5 finished with value: 0.14425341127918542 and parameters: {'hidden_size': 175, 'num_layers': 3, 'dropout': 0.42918054157297825, 'lr': 0.0034158851386603467, 'batch_size': 64}. Best is trial 3 with value: 0.13388605746189633.\n",
            "[I 2025-12-05 05:15:54,940] Trial 6 finished with value: 0.1344937372752634 and parameters: {'hidden_size': 261, 'num_layers': 3, 'dropout': 0.13734638900793145, 'lr': 0.004206216644172912, 'batch_size': 32}. Best is trial 3 with value: 0.13388605746189633.\n",
            "[I 2025-12-05 05:16:08,432] Trial 7 finished with value: 0.37352914400287196 and parameters: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.3628738679502094, 'lr': 0.00016807429007290495, 'batch_size': 32}. Best is trial 3 with value: 0.13388605746189633.\n",
            "[I 2025-12-05 05:16:20,098] Trial 8 finished with value: 0.33136288485528825 and parameters: {'hidden_size': 173, 'num_layers': 1, 'dropout': 0.4669369142551594, 'lr': 0.00010560869212883533, 'batch_size': 32}. Best is trial 3 with value: 0.13388605746189633.\n",
            "[I 2025-12-05 05:16:31,619] Trial 9 finished with value: 0.1311093135170733 and parameters: {'hidden_size': 475, 'num_layers': 1, 'dropout': 0.1063718183476282, 'lr': 0.005898459341825242, 'batch_size': 32}. Best is trial 9 with value: 0.1311093135170733.\n",
            "[I 2025-12-05 05:16:36,013] Trial 10 finished with value: 0.1359511488920334 and parameters: {'hidden_size': 461, 'num_layers': 1, 'dropout': 0.2131956488264437, 'lr': 0.009888843781872344, 'batch_size': 128}. Best is trial 9 with value: 0.1311093135170733.\n",
            "[I 2025-12-05 05:16:44,003] Trial 11 finished with value: 0.10246609262515606 and parameters: {'hidden_size': 361, 'num_layers': 2, 'dropout': 0.2330884976490631, 'lr': 0.0009285010115745951, 'batch_size': 64}. Best is trial 11 with value: 0.10246609262515606.\n",
            "[I 2025-12-05 05:16:51,856] Trial 12 finished with value: 0.09895137827941021 and parameters: {'hidden_size': 373, 'num_layers': 2, 'dropout': 0.218305528084069, 'lr': 0.0015161827712138465, 'batch_size': 64}. Best is trial 12 with value: 0.09895137827941021.\n",
            "[I 2025-12-05 05:16:59,667] Trial 13 finished with value: 0.09927213123154653 and parameters: {'hidden_size': 362, 'num_layers': 2, 'dropout': 0.260144741888854, 'lr': 0.0013729573629468503, 'batch_size': 64}. Best is trial 12 with value: 0.09895137827941021.\n",
            "[I 2025-12-05 05:17:07,435] Trial 14 finished with value: 0.09801971552123924 and parameters: {'hidden_size': 343, 'num_layers': 2, 'dropout': 0.28319417648906664, 'lr': 0.0017897493066372295, 'batch_size': 64}. Best is trial 14 with value: 0.09801971552123924.\n",
            "[I 2025-12-05 05:17:15,218] Trial 15 finished with value: 0.0981920816129754 and parameters: {'hidden_size': 346, 'num_layers': 2, 'dropout': 0.30140482040306055, 'lr': 0.002438632570948919, 'batch_size': 64}. Best is trial 14 with value: 0.09801971552123924.\n",
            "[I 2025-12-05 05:17:23,071] Trial 16 finished with value: 0.09833846967416386 and parameters: {'hidden_size': 322, 'num_layers': 2, 'dropout': 0.29711095451285213, 'lr': 0.0029056115394081833, 'batch_size': 64}. Best is trial 14 with value: 0.09801971552123924.\n",
            "[I 2025-12-05 05:17:31,889] Trial 17 finished with value: 0.11502924988692062 and parameters: {'hidden_size': 419, 'num_layers': 3, 'dropout': 0.3162449861117552, 'lr': 0.0024398117488740726, 'batch_size': 64}. Best is trial 14 with value: 0.09801971552123924.\n",
            "[I 2025-12-05 05:17:37,225] Trial 18 finished with value: 0.1319226501456764 and parameters: {'hidden_size': 302, 'num_layers': 3, 'dropout': 0.3217127263715599, 'lr': 0.005464356143991359, 'batch_size': 128}. Best is trial 14 with value: 0.09801971552123924.\n",
            "[I 2025-12-05 05:17:45,093] Trial 19 finished with value: 0.13340483861055202 and parameters: {'hidden_size': 409, 'num_layers': 2, 'dropout': 0.16885761036843447, 'lr': 0.0003114645865178796, 'batch_size': 64}. Best is trial 14 with value: 0.09801971552123924.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best MLP hyperparameters: {'hidden_size': 343, 'num_layers': 2, 'dropout': 0.28319417648906664, 'lr': 0.0017897493066372295, 'batch_size': 64}\n",
            "Best MLP validation loss: 0.09801971552123924\n"
          ]
        }
      ],
      "source": [
        "#Hyperparameter tuning for MLP\n",
        "# ==============================\n",
        "# Hyperparameter tuning: MLP\n",
        "# ==============================\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import optuna\n",
        "\n",
        "# ---------- Dataset ----------\n",
        "class ASLMLPDataset(Dataset):\n",
        "    def __init__(self, npz_path):\n",
        "        data = np.load(npz_path)\n",
        "        self.X = data[\"X\"]     # (N, 42)\n",
        "        self.y = data[\"y\"]     # (N,)\n",
        "\n",
        "        # Assertions to ensure data is in the expected (N, 42) format\n",
        "        assert self.X.ndim == 2, f\"X must be 2-dimensional (N, features), but got {self.X.ndim} dimensions\"\n",
        "        assert self.X.shape[1] == 42, f\"Expected 42 features per sample, but got {self.X.shape[1]}\"\n",
        "        assert len(self.X) == len(self.y), \"X and y must have same length\"\n",
        "\n",
        "        # The X data is already flattened (N, 42) as required for an MLP input\n",
        "        # No further reshaping needed for self.X\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.from_numpy(self.X[idx])          # (42,)\n",
        "        y = torch.tensor(self.y[idx], dtype=torch.long)\n",
        "        return x, y\n",
        "\n",
        "# ---------- Model ----------\n",
        "class ASLMLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        in_dim = input_size\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            layers.append(nn.Linear(in_dim, hidden_size))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            in_dim = hidden_size\n",
        "\n",
        "        layers.append(nn.Linear(in_dim, num_classes))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, input_size)\n",
        "        return self.net(x)\n",
        "\n",
        "# ---------- Setup ----------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using:\", device)\n",
        "\n",
        "train_dataset = ASLMLPDataset(\"/content/drive/MyDrive/Duke University/CV-Group6/train.npz\")\n",
        "val_dataset   = ASLMLPDataset(\"/content/drive/MyDrive/Duke University/CV-Group6/val.npz\")\n",
        "\n",
        "input_size  = train_dataset.X.shape[1]\n",
        "num_classes = len(np.unique(train_dataset.y))\n",
        "\n",
        "# ---------- Optuna objective ----------\n",
        "def objective_mlp(trial):\n",
        "    # Hyperparameters to tune\n",
        "    hidden_size = trial.suggest_int(\"hidden_size\", 64, 512)\n",
        "    num_layers  = trial.suggest_int(\"num_layers\", 1, 3)\n",
        "    dropout     = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
        "    lr          = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "    batch_size  = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = ASLMLPClassifier(\n",
        "        input_size=input_size,\n",
        "        hidden_size=hidden_size,\n",
        "        num_layers=num_layers,\n",
        "        num_classes=num_classes,\n",
        "        dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    num_epochs = 5  # keep small for tuning speed\n",
        "\n",
        "    # ---- Train for a few epochs ----\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(X_batch)\n",
        "            loss = criterion(logits, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # ---- Validation loss (objective) ----\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            logits = model(X_batch)\n",
        "            loss = criterion(logits, y_batch)\n",
        "            val_loss += loss.item() * X_batch.size(0)\n",
        "            val_total += X_batch.size(0)\n",
        "\n",
        "    val_loss /= val_total\n",
        "    return val_loss  # Optuna will MINIMIZE this\n",
        "\n",
        "# ---------- Run study ----------\n",
        "study_mlp = optuna.create_study(direction=\"minimize\")\n",
        "study_mlp.optimize(objective_mlp, n_trials=20)\n",
        "\n",
        "print(\"Best MLP hyperparameters:\", study_mlp.best_params)\n",
        "print(\"Best MLP validation loss:\", study_mlp.best_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K6oUK1z7AQs",
        "outputId": "7fba9ac4-d22c-4a7a-c8c0-fabdf5595e08"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-05 05:17:45,203] A new study created in memory with name: no-name-39c5b829-d775-40b2-a578-df6aa29e4c06\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-05 05:17:57,188] Trial 0 finished with value: 0.14070784345179974 and parameters: {'hidden_size': 65, 'num_layers': 2, 'dropout': 0.3605597572560686, 'lr': 0.009069185165078967, 'batch_size': 64}. Best is trial 0 with value: 0.14070784345179974.\n",
            "[I 2025-12-05 05:18:07,300] Trial 1 finished with value: 0.12937650104822915 and parameters: {'hidden_size': 68, 'num_layers': 1, 'dropout': 0.27877644347486863, 'lr': 0.001427299955001774, 'batch_size': 64}. Best is trial 1 with value: 0.12937650104822915.\n",
            "[I 2025-12-05 05:18:14,922] Trial 2 finished with value: 0.19702394620744054 and parameters: {'hidden_size': 126, 'num_layers': 3, 'dropout': 0.2719916277679831, 'lr': 0.0007737335282986118, 'batch_size': 128}. Best is trial 1 with value: 0.12937650104822915.\n",
            "[I 2025-12-05 05:18:28,434] Trial 3 finished with value: 0.12278247959232153 and parameters: {'hidden_size': 192, 'num_layers': 3, 'dropout': 0.13891388166791696, 'lr': 0.002334004793405831, 'batch_size': 64}. Best is trial 3 with value: 0.12278247959232153.\n",
            "[I 2025-12-05 05:18:35,464] Trial 4 finished with value: 0.2015314081427223 and parameters: {'hidden_size': 209, 'num_layers': 2, 'dropout': 0.3401145288402009, 'lr': 0.0003063131167409943, 'batch_size': 128}. Best is trial 3 with value: 0.12278247959232153.\n",
            "[I 2025-12-05 05:18:42,328] Trial 5 finished with value: 0.11861118248100588 and parameters: {'hidden_size': 168, 'num_layers': 2, 'dropout': 0.20994422531818815, 'lr': 0.0013261580276458442, 'batch_size': 128}. Best is trial 5 with value: 0.11861118248100588.\n",
            "[I 2025-12-05 05:19:03,862] Trial 6 finished with value: 0.11620913457462873 and parameters: {'hidden_size': 183, 'num_layers': 2, 'dropout': 0.43082401132495385, 'lr': 0.002739861414525504, 'batch_size': 32}. Best is trial 6 with value: 0.11620913457462873.\n",
            "[I 2025-12-05 05:19:11,581] Trial 7 finished with value: 0.35809297572352927 and parameters: {'hidden_size': 180, 'num_layers': 3, 'dropout': 0.4280070085840111, 'lr': 0.00026804520555745356, 'batch_size': 128}. Best is trial 6 with value: 0.11620913457462873.\n",
            "[I 2025-12-05 05:19:18,514] Trial 8 finished with value: 0.1030330642778984 and parameters: {'hidden_size': 164, 'num_layers': 2, 'dropout': 0.2800588556638919, 'lr': 0.006729345215234094, 'batch_size': 128}. Best is trial 8 with value: 0.1030330642778984.\n",
            "[I 2025-12-05 05:19:24,752] Trial 9 finished with value: 0.10181958886145051 and parameters: {'hidden_size': 236, 'num_layers': 1, 'dropout': 0.42242153235427216, 'lr': 0.004123486539162893, 'batch_size': 128}. Best is trial 9 with value: 0.10181958886145051.\n",
            "[I 2025-12-05 05:19:43,614] Trial 10 finished with value: 0.1060183499348611 and parameters: {'hidden_size': 255, 'num_layers': 1, 'dropout': 0.49822470479832903, 'lr': 0.00381475129145439, 'batch_size': 32}. Best is trial 9 with value: 0.10181958886145051.\n",
            "[I 2025-12-05 05:19:49,805] Trial 11 finished with value: 0.10971564780195762 and parameters: {'hidden_size': 254, 'num_layers': 1, 'dropout': 0.19629190703064583, 'lr': 0.008028856032781872, 'batch_size': 128}. Best is trial 9 with value: 0.10181958886145051.\n",
            "[I 2025-12-05 05:19:55,819] Trial 12 finished with value: 0.11356961263544456 and parameters: {'hidden_size': 127, 'num_layers': 1, 'dropout': 0.39233524696957933, 'lr': 0.0058500430346076675, 'batch_size': 128}. Best is trial 9 with value: 0.10181958886145051.\n",
            "[I 2025-12-05 05:20:02,109] Trial 13 finished with value: 0.10028495022171026 and parameters: {'hidden_size': 227, 'num_layers': 1, 'dropout': 0.3096817900972546, 'lr': 0.004331507540025564, 'batch_size': 128}. Best is trial 13 with value: 0.10028495022171026.\n",
            "[I 2025-12-05 05:20:08,343] Trial 14 finished with value: 0.3467896722212523 and parameters: {'hidden_size': 220, 'num_layers': 1, 'dropout': 0.46255686465683576, 'lr': 0.00012089079035835053, 'batch_size': 128}. Best is trial 13 with value: 0.10028495022171026.\n",
            "[I 2025-12-05 05:20:27,277] Trial 15 finished with value: 0.11262483306526776 and parameters: {'hidden_size': 228, 'num_layers': 1, 'dropout': 0.3378422514967846, 'lr': 0.000665597816614269, 'batch_size': 32}. Best is trial 13 with value: 0.10028495022171026.\n",
            "[I 2025-12-05 05:20:33,527] Trial 16 finished with value: 0.10734175881538205 and parameters: {'hidden_size': 235, 'num_layers': 1, 'dropout': 0.22004279502206997, 'lr': 0.0027263952760803235, 'batch_size': 128}. Best is trial 13 with value: 0.10028495022171026.\n",
            "[I 2025-12-05 05:20:39,577] Trial 17 finished with value: 0.10122358837460507 and parameters: {'hidden_size': 143, 'num_layers': 1, 'dropout': 0.38477179232077263, 'lr': 0.004190039973270268, 'batch_size': 128}. Best is trial 13 with value: 0.10028495022171026.\n",
            "[I 2025-12-05 05:20:58,044] Trial 18 finished with value: 0.10585504235578827 and parameters: {'hidden_size': 139, 'num_layers': 1, 'dropout': 0.31695195357929695, 'lr': 0.0017561967714599805, 'batch_size': 32}. Best is trial 13 with value: 0.10028495022171026.\n",
            "[I 2025-12-05 05:21:09,657] Trial 19 finished with value: 0.11863103790781537 and parameters: {'hidden_size': 106, 'num_layers': 2, 'dropout': 0.37755966948692743, 'lr': 0.004852904677121224, 'batch_size': 64}. Best is trial 13 with value: 0.10028495022171026.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best LSTM hyperparameters: {'hidden_size': 227, 'num_layers': 1, 'dropout': 0.3096817900972546, 'lr': 0.004331507540025564, 'batch_size': 128}\n",
            "Best LSTM validation loss: 0.10028495022171026\n"
          ]
        }
      ],
      "source": [
        "#Hyperparameter Tuning for LSTM\n",
        "# ==============================\n",
        "# Hyperparameter tuning: LSTM\n",
        "# ==============================\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import optuna\n",
        "\n",
        "# ---------- Dataset ----------\n",
        "class ASLLSTMDataset(Dataset):\n",
        "    def __init__(self, npz_path):\n",
        "        data = np.load(npz_path)\n",
        "        self.X = data[\"X\"]     # (N, 42)\n",
        "        self.y = data[\"y\"]     # (N,)\n",
        "\n",
        "        assert self.X.ndim == 2, f\"X must be 2-dimensional (N, features), but got {self.X.ndim} dimensions\"\n",
        "        assert self.X.shape[1] == 42, f\"Expected 42 features per sample, but got {self.X.shape[1]}\"\n",
        "        assert len(self.X) == len(self.y), \"X and y must have same length\"\n",
        "\n",
        "        # Reshape for LSTM: (N, 42) -> (N, T=1, features=42)\n",
        "        # Each static image is treated as a sequence of length 1\n",
        "        self.X = self.X[:, np.newaxis, :].astype(np.float32) # Shape becomes (N, 1, 42)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.from_numpy(self.X[idx])          # (T=1, 42)\n",
        "        y = torch.tensor(self.y[idx], dtype=torch.long)\n",
        "        return x, y\n",
        "\n",
        "# ---------- LSTM Model ----------\n",
        "class ASLLSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, T, input_size)\n",
        "        out, (h_n, c_n) = self.lstm(x)\n",
        "        last_hidden = h_n[-1]  # (batch, hidden_size)\n",
        "        return self.fc(last_hidden)\n",
        "\n",
        "# ---------- Setup ----------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using:\", device)\n",
        "\n",
        "train_dataset = ASLLSTMDataset(\"/content/drive/MyDrive/Duke University/CV-Group6/train.npz\")\n",
        "val_dataset   = ASLLSTMDataset(\"/content/drive/MyDrive/Duke University/CV-Group6/val.npz\")\n",
        "\n",
        "# Correctly derive input_size from the dataset's X shape\n",
        "# self.X has shape (N, 1, 42), so X.shape[2] gives 42\n",
        "_, _, input_size = train_dataset.X.shape\n",
        "num_classes = len(np.unique(train_dataset.y))\n",
        "\n",
        "# ---------- Optuna objective ----------\n",
        "def objective_lstm(trial):\n",
        "    # Hyperparameters to tune\n",
        "    hidden_size = trial.suggest_int(\"hidden_size\", 64, 256)\n",
        "    num_layers  = trial.suggest_int(\"num_layers\", 1, 3)\n",
        "    dropout     = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
        "    lr          = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "    batch_size  = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = ASLLSTMClassifier(\n",
        "        input_size=input_size,\n",
        "        hidden_size=hidden_size,\n",
        "        num_layers=num_layers,\n",
        "        num_classes=num_classes,\n",
        "        dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    num_epochs = 5  # small for tuning\n",
        "\n",
        "    # ---- Train for a few epochs ----\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(X_batch)\n",
        "            loss = criterion(logits, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # ---- Validation loss (objective) ----\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            logits = model(X_batch)\n",
        "            loss = criterion(logits, y_batch)\n",
        "            val_loss += loss.item() * X_batch.size(0)\n",
        "            val_total += X_batch.size(0)\n",
        "\n",
        "    val_loss /= val_total\n",
        "    return val_loss\n",
        "\n",
        "# ---------- Run study ----------\n",
        "study_lstm = optuna.create_study(direction=\"minimize\")\n",
        "study_lstm.optimize(objective_lstm, n_trials=20)\n",
        "\n",
        "print(\"Best LSTM hyperparameters:\", study_lstm.best_params)\n",
        "print(\"Best LSTM validation loss:\", study_lstm.best_value)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkPs4-c3FElm"
      },
      "source": [
        "# Predictive Models (CNN/LSTM) without mediapipe processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLGF2kEtcX0U"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNfFF2MrBu0O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "# =========================\n",
        "# 0. Mount Google Drive (run this once per Colab session)\n",
        "# =========================\n",
        "\n",
        "# Set your dataset folder paths in Drive\n",
        "train_folder = \"/content/drive/MyDrive/Duke University/CV-Group6/train_dataset\"   # <-- edit to your path\n",
        "val_folder   = \"/content/drive/MyDrive/Duke University/CV-Group6/val_dataset\"     # <-- edit to your path\n",
        "\n",
        "# =========================\n",
        "# 1. Load tf.data Datasets saved as tensors\n",
        "# =========================\n",
        "\n",
        "train_ds = tf.data.Dataset.load(train_folder)\n",
        "val_ds   = tf.data.Dataset.load(val_folder)\n",
        "\n",
        "# At this point, train_ds and val_ds are already batched datasets of (images, labels)\n",
        "# because you saved them from image_dataset_from_directory with batch_size=32.\n",
        "\n",
        "# =========================\n",
        "# 2. Inspect one batch to infer shapes\n",
        "# =========================\n",
        "\n",
        "for images, labels in train_ds.take(1):\n",
        "    print(\"Image batch shape:\", images.shape)\n",
        "    print(\"Label batch shape:\", labels.shape)\n",
        "    img_height = images.shape[1]\n",
        "    img_width  = images.shape[2]\n",
        "    num_channels = images.shape[3]          # 1 for grayscale, 3 for RGB\n",
        "    num_classes = labels.shape[-1]          # because labels are one-hot (categorical)\n",
        "    break\n",
        "\n",
        "print(\"img_height:\", img_height)\n",
        "print(\"img_width:\", img_width)\n",
        "print(\"num_channels:\", num_channels)\n",
        "print(\"num_classes:\", num_classes)\n",
        "\n",
        "# =========================\n",
        "# 3. Prepare datasets (shuffle, cache, prefetch)\n",
        "# =========================\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# You can shuffle at the batch level; if you want true example-level shuffle:\n",
        "# train_ds = train_ds.unbatch().shuffle(10000).batch(32)\n",
        "train_ds = train_ds.shuffle(1000).cache().prefetch(AUTOTUNE)\n",
        "val_ds   = val_ds.cache().prefetch(AUTOTUNE)\n",
        "\n",
        "# =========================\n",
        "# 4. Data augmentation (automatic rotation)\n",
        "# =========================\n",
        "\n",
        "# factor=0.1 ‚âà ¬±10% of 180¬∞ ‚Üí about ¬±18¬∞\n",
        "# Increase to 0.25 (~¬±45¬∞) if your ASL images can tolerate more rotation.\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomRotation(factor=0.1),\n",
        "    # You can add more if you want:\n",
        "    # layers.RandomZoom(0.1),\n",
        "    # layers.RandomTranslation(0.1, 0.1),\n",
        "])\n",
        "\n",
        "# =========================\n",
        "# 5. Define the CNN model (with rotation)\n",
        "# =========================\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(img_height, img_width, num_channels)),\n",
        "\n",
        "    # üîÅ Apply random rotations during training only\n",
        "    data_augmentation,\n",
        "\n",
        "    # Normalize pixels 0‚Äì255 ‚Üí 0‚Äì1\n",
        "    layers.Rescaling(1./255),\n",
        "\n",
        "    layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\"),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "# IMPORTANT: labels are one-hot (because you used label_mode=\"categorical\")\n",
        "# ‚Üí use categorical_crossentropy\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\n",
        "        \"accuracy\",\n",
        "        tf.keras.metrics.AUC(\n",
        "            name=\"auc_ovr\",\n",
        "            multi_label=True,      # because y_true is one-hot with shape (batch, num_classes)\n",
        "            from_logits=False\n",
        "        ),\n",
        "        tfa.metrics.F1Score(\n",
        "            num_classes=num_classes,\n",
        "            average=\"macro\",\n",
        "            name=\"f1_macro\"\n",
        "        ),\n",
        "    ],\n",
        ")\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# =========================\n",
        "# 6. Train the model\n",
        "# =========================\n",
        "\n",
        "epochs = 15\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 7. Save the model\n",
        "# =========================\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/Duke University/CV-Group6/cnn_from_saved_tensors_with_rotation.h5\"\n",
        "model.save(model_path)\n",
        "print(f\"‚úÖ Model saved to {model_path}\")\n",
        "\n",
        "# =========================\n",
        "# 8. Predict on a single tensor image (from a batch)\n",
        "# =========================\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def predict_from_tensor(model, img_tensor, class_names=None):\n",
        "    \"\"\"\n",
        "    img_tensor: single image tensor, shape (H, W, C), values 0‚Äì255 or 0‚Äì1\n",
        "    \"\"\"\n",
        "    if img_tensor.ndim == 3:\n",
        "        img_tensor = np.expand_dims(img_tensor, axis=0)  # (1, H, W, C)\n",
        "\n",
        "    img_tensor = img_tensor.astype(\"float32\")\n",
        "    preds = model.predict(img_tensor)\n",
        "    pred_idx = int(np.argmax(preds[0]))\n",
        "    confidence = float(np.max(preds[0]))\n",
        "\n",
        "    if class_names is not None:\n",
        "        pred_class = class_names[pred_idx]\n",
        "    else:\n",
        "        pred_class = pred_idx\n",
        "\n",
        "    return pred_class, confidence\n",
        "\n",
        "# Example usage: use one batch from val_ds\n",
        "# for batch_images, batch_labels in val_ds.take(1):\n",
        "#     img = batch_images[0].numpy()\n",
        "#     pred, conf = predict_from_tensor(model, img)\n",
        "#     print(\"Predicted class index:\", pred, \"confidence:\", conf)\n",
        "#     break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzcO0eKkdxvk"
      },
      "source": [
        "# Loading Model and Evaluating Performance on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNLtsotgcoFl"
      },
      "outputs": [],
      "source": [
        "#Load Model and Evaluate performance on Test dataset\n",
        "model_path = \"/content/drive/MyDrive/Duke University/CV-Group6/cnn_from_saved_tensors_with_rotation.h5\"\n",
        "model = keras.models.load_model(model_path)\n",
        "print(\"model succesfully loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DE33roKdUL0"
      },
      "outputs": [],
      "source": [
        "test_ds = tf.data.Dataset.load(\"/content/drive/MyDrive/Duke University/CV-Group6/test_dataset\")\n",
        "# Inspect one batch to get shape & num_classes\n",
        "for images, labels in test_ds.take(1):\n",
        "    img_height = images.shape[1]\n",
        "    img_width  = images.shape[2]\n",
        "    num_channels = images.shape[3]\n",
        "    num_classes = labels.shape[-1]   # one-hot labels\n",
        "    break\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "test_ds = test_ds.cache().prefetch(AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX9bNC7RdfnC"
      },
      "outputs": [],
      "source": [
        "#Implement model and evaluate performance\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\n",
        "        \"accuracy\",\n",
        "        tf.keras.metrics.AUC(\n",
        "            name=\"auc_ovr\",\n",
        "            multi_label=True,\n",
        "            from_logits=False,\n",
        "        ),\n",
        "        tfa.metrics.F1Score(\n",
        "            num_classes=num_classes,\n",
        "            average=\"macro\",\n",
        "            name=\"f1_macro\",\n",
        "        ),\n",
        "    ],\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "results = model.evaluate(test_ds)\n",
        "print(dict(zip(model.metrics_names, results)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAAB2gdMd5Oh"
      },
      "outputs": [],
      "source": [
        "#Make prediction on a random Image\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
